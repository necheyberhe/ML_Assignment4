{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c44d416d",
   "metadata": {},
   "source": [
    "Step 1: Setup and Data Download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f00823dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Notebook-cell version: VGG19 transfer learning on Oxford 102 Flowers\n",
    "- Random split 50/25/25\n",
    "- Run twice by calling run_experiment(split_seed=1) and run_experiment(split_seed=2)\n",
    "- Saves curves + checkpoint into out_dir\n",
    "\"\"\"\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Dataset, Subset\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import scipy.io as sio\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "268fc0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Flowers102Local(Dataset):\n",
    "    \"\"\"\n",
    "    Local Oxford 102 Flowers dataset:\n",
    "    root/\n",
    "      jpg/\n",
    "      imagelabels.mat\n",
    "      setid.mat\n",
    "    \"\"\"\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = Path(root)\n",
    "        self.img_dir = self.root / \"jpg\"\n",
    "        self.transform = transform\n",
    "\n",
    "        mat = sio.loadmat(self.root / \"imagelabels.mat\")\n",
    "        labels = mat[\"labels\"].squeeze().astype(int)  # 1..102\n",
    "        self.labels = (labels - 1).tolist()           # 0..101\n",
    "\n",
    "        self.image_paths = [\n",
    "            self.img_dir / f\"image_{i:05d}.jpg\"\n",
    "            for i in range(1, len(self.labels) + 1)\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        y = self.labels[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6b8873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Dataset utilities\n",
    "# -----------------------------\n",
    "@dataclass\n",
    "class SplitIndices:\n",
    "    train: List[int]\n",
    "    val: List[int]\n",
    "    test: List[int]\n",
    "\n",
    "\n",
    "class TransformOverrideDataset(Dataset):\n",
    "    def __init__(self, base: Dataset, transform):\n",
    "        self.base = base\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.base[idx]\n",
    "        if self.transform is not None:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e65cddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_flowers102_all(root: str) -> Dataset:\n",
    "    return Flowers102Local(root=root, transform=None)\n",
    "\n",
    "\n",
    "def make_random_split_indices(n: int, split_seed: int) -> SplitIndices:\n",
    "    g = torch.Generator().manual_seed(split_seed)\n",
    "    perm = torch.randperm(n, generator=g).tolist()\n",
    "\n",
    "    n_train = int(0.50 * n)\n",
    "    n_val = int(0.25 * n)\n",
    "    n_test = n - n_train - n_val\n",
    "\n",
    "    train_idx = perm[:n_train]\n",
    "    val_idx = perm[n_train:n_train + n_val]\n",
    "    test_idx = perm[n_train + n_val:n_train + n_val + n_test]\n",
    "\n",
    "    return SplitIndices(train=train_idx, val=val_idx, test=test_idx)\n",
    "\n",
    "\n",
    "def save_split_indices(path: str, split: SplitIndices) -> None:\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"train\": split.train, \"val\": split.val, \"test\": split.test}, f)\n",
    "\n",
    "\n",
    "def load_split_indices(path: str) -> SplitIndices:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        obj = json.load(f)\n",
    "    return SplitIndices(train=obj[\"train\"], val=obj[\"val\"], test=obj[\"test\"])\n",
    "\n",
    "\n",
    "def build_transforms(img_size: int = 224):\n",
    "    imagenet_mean = [0.485, 0.456, 0.406]\n",
    "    imagenet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "    train_tf = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.02),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
    "    ])\n",
    "\n",
    "    eval_tf = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
    "    ])\n",
    "\n",
    "    return train_tf, eval_tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "681b4fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loaders(\n",
    "    root: str,\n",
    "    batch_size: int,\n",
    "    num_workers: int,\n",
    "    split_seed: int,\n",
    "    split_cache_path: str,\n",
    "    img_size: int = 224,\n",
    ") -> Tuple[DataLoader, DataLoader, DataLoader, SplitIndices]:\n",
    "    base_all = load_flowers102_all(root=root)\n",
    "    n = len(base_all)\n",
    "\n",
    "    if os.path.isfile(split_cache_path):\n",
    "        split = load_split_indices(split_cache_path)\n",
    "    else:\n",
    "        split = make_random_split_indices(n=n, split_seed=split_seed)\n",
    "        save_split_indices(split_cache_path, split)\n",
    "\n",
    "    train_tf, eval_tf = build_transforms(img_size=img_size)\n",
    "\n",
    "    train_ds = TransformOverrideDataset(Subset(base_all, split.train), transform=train_tf)\n",
    "    val_ds   = TransformOverrideDataset(Subset(base_all, split.val), transform=eval_tf)\n",
    "    test_ds  = TransformOverrideDataset(Subset(base_all, split.test), transform=eval_tf)\n",
    "\n",
    "    # In Windows notebooks, num_workers>0 can cause issues. Use 0 unless you know it's stable.\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=num_workers, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False,\n",
    "                              num_workers=num_workers, pin_memory=True)\n",
    "    test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False,\n",
    "                              num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76ae9df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Model\n",
    "# -----------------------------\n",
    "def build_vgg19_classifier(num_classes: int = 102, freeze_features: bool = True) -> nn.Module:\n",
    "    model = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    if freeze_features:\n",
    "        for p in model.features.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    in_features = model.classifier[-1].in_features\n",
    "    model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a9089ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Train/Eval loops\n",
    "# -----------------------------\n",
    "@torch.no_grad()\n",
    "def evaluate(model: nn.Module, loader: DataLoader, device: torch.device, criterion: nn.Module) -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += x.size(0)\n",
    "\n",
    "    return total_loss / max(1, total), correct / max(1, total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67efd1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    device: torch.device,\n",
    "    criterion: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    ") -> Tuple[float, float]:\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += x.size(0)\n",
    "\n",
    "    return total_loss / max(1, total), correct / max(1, total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "568d4d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_curves(out_dir: str, history: Dict[str, List[float]]) -> None:\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(history[\"train_acc\"], label=\"train\")\n",
    "    plt.plot(history[\"val_acc\"], label=\"val\")\n",
    "    plt.plot(history[\"test_acc\"], label=\"test\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, \"accuracy_vgg19.png\"), dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(history[\"train_loss\"], label=\"train\")\n",
    "    plt.plot(history[\"val_loss\"], label=\"val\")\n",
    "    plt.plot(history[\"test_loss\"], label=\"test\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"cross_entropy\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, \"loss_vgg19.png\"), dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "    with open(os.path.join(out_dir, \"history_vgg19.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(history, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8154c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_checkpoint(path: str, model: nn.Module, optimizer: optim.Optimizer, epoch: int, best_val_acc: float) -> None:\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    torch.save(\n",
    "        {\"epoch\": epoch, \"model_state\": model.state_dict(),\n",
    "         \"optimizer_state\": optimizer.state_dict(), \"best_val_acc\": best_val_acc},\n",
    "        path,\n",
    "    )\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_proba(model: nn.Module, images: torch.Tensor, device: torch.device) -> torch.Tensor:\n",
    "    model.eval()\n",
    "    images = images.to(device)\n",
    "    logits = model(images)\n",
    "    return torch.softmax(logits, dim=1).cpu()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c2edb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_yolov5_classifier(num_classes: int = 102, freeze_backbone: bool = True) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Build YOLOv5-based classifier using CSPDarknet as backbone\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load YOLOv5 model\n",
    "        print(\"Loading YOLOv5...\")\n",
    "        yolo = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True, verbose=False)\n",
    "        \n",
    "        # Extract backbone (CSPDarknet)\n",
    "        backbone = yolo.model.model[:10]\n",
    "        \n",
    "        if freeze_backbone:\n",
    "            for param in backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Determine output channels\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.randn(1, 3, 224, 224)\n",
    "            features = backbone(dummy)\n",
    "            in_features = features.shape[1] * features.shape[2] * features.shape[3]\n",
    "            out_channels = features.shape[1]\n",
    "        \n",
    "        # Build classifier head\n",
    "        classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(out_channels, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        class YOLOv5Model(nn.Module):\n",
    "            def __init__(self, backbone, classifier):\n",
    "                super().__init__()\n",
    "                self.backbone = backbone\n",
    "                self.classifier = classifier\n",
    "            \n",
    "            def forward(self, x):\n",
    "                features = self.backbone(x)\n",
    "                return self.classifier(features)\n",
    "        \n",
    "        return YOLOv5Model(backbone, classifier)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Could not load YOLOv5: {e}\")\n",
    "        print(\"Falling back to MobileNetV3 as alternative\")\n",
    "        # Fallback model\n",
    "        mobilenet = models.mobilenet_v3_small(pretrained=True)\n",
    "        \n",
    "        if freeze_backbone:\n",
    "            for param in mobilenet.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Replace classifier\n",
    "        in_features = mobilenet.classifier[-1].in_features\n",
    "        mobilenet.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "        \n",
    "        return mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "667a8b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def build_yolov5_cls_classifier(\n",
    "    num_classes: int = 102,\n",
    "    freeze_backbone: bool = True,\n",
    "    weights: str = \"yolov5s-cls.pt\",\n",
    ") -> nn.Module:\n",
    "    \"\"\"\n",
    "    REAL YOLOv5 classifier using YOLOv5-CLS checkpoints (e.g., yolov5s-cls.pt).\n",
    "\n",
    "    - No fallback. If YOLOv5-CLS can't load, it raises an error.\n",
    "    - Replaces the final classifier layer to num_classes.\n",
    "    \"\"\"\n",
    "    print(f\"Loading REAL YOLOv5-CLS checkpoint: {weights}\")\n",
    "\n",
    "    # Load YOLOv5-CLS model from Ultralytics YOLOv5 repo via torch.hub\n",
    "    yolo = torch.hub.load(\n",
    "        \"ultralytics/yolov5\",\n",
    "        \"custom\",\n",
    "        path=weights,          # can be local path or model name if supported\n",
    "        autoshape=False,       # raw torch model for training\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    model = getattr(yolo, \"model\", None)\n",
    "    if model is None:\n",
    "        raise RuntimeError(\"Unexpected YOLOv5 hub return: missing `.model` attribute.\")\n",
    "\n",
    "    # For YOLOv5-CLS, last layer is typically a Classify module with `.linear`\n",
    "    head = model.model[-1]\n",
    "    if not hasattr(head, \"linear\"):\n",
    "        raise RuntimeError(\n",
    "            \"This does not look like a YOLOv5-CLS checkpoint (missing head.linear). \"\n",
    "            \"You probably loaded a detection checkpoint (e.g., yolov5s.pt). \"\n",
    "            \"Use yolov5s-cls.pt / yolov5m-cls.pt / yolov5l-cls.pt etc.\"\n",
    "        )\n",
    "\n",
    "    # Replace classifier\n",
    "    in_features = head.linear.in_features\n",
    "    head.linear = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    # Freeze backbone if requested\n",
    "    if freeze_backbone:\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in head.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bff9727d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:23: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:23: SyntaxWarning: invalid escape sequence '\\M'\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_3424\\272774182.py:23: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  data_root:D:\\Masters Study\\1styear\\2025\\Machine Learning\\Assignment4\\Assignment4\\data\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "#  \"main\"\n",
    "# -----------------------------\n",
    "def run_experiment(\n",
    "    model_type: str = \"vgg19\",  # \"vgg19\" or \"yolov5\"\n",
    "    data_root: str = \"./data\",\n",
    "    out_dir: str = \"./results/vgg19_seed1\",\n",
    "    epochs: int = 35,\n",
    "    batch_size: int = 32,\n",
    "    lr: float = 1e-4,\n",
    "    weight_decay: float = 0.0,\n",
    "    num_workers: int = 0,\n",
    "    img_size: int = 224,\n",
    "    split_seed: int = 1,\n",
    "    freeze_backbone: bool = True,\n",
    "    early_stop_patience: int = 7,\n",
    "    device: str = \"cuda\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Main training function for flower classification.\n",
    "    \n",
    "    Args:\n",
    "        data_root:D:\\Masters Study\\1styear\\2025\\Machine Learning\\Assignment4\\Assignment4\\data\n",
    "        out_dir: D:\\Masters Study\\1styear\\2025\\Machine Learning\\Assignment4\\Assignment4\\results\n",
    "        epochs: Maximum number of training epochs\n",
    "        batch_size: Batch size for training\n",
    "        lr: Learning rate (will be adjusted based on model_type)\n",
    "        weight_decay: Weight decay for optimizer\n",
    "        num_workers: Number of data loader workers\n",
    "        img_size: Input image size\n",
    "        split_seed: Random seed for data split\n",
    "        freeze_backbone: Whether to freeze pre-trained backbone\n",
    "        early_stop_patience: Early stopping patience\n",
    "        device: \"cuda\" or \"cpu\"\n",
    "    \n",
    "    Returns:\n",
    "        history: Dictionary with training history\n",
    "        ckpt_path: Path to best model checkpoint\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set device\n",
    "    if device == \"cuda\" and not torch.cuda.is_available():\n",
    "        print(\"CUDA requested but not available. Falling back to CPU.\")\n",
    "        device = \"cpu\"\n",
    "    device_t = torch.device(device)\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    \n",
    "    # Set random seeds for reproducibility\n",
    "    set_seed(split_seed)\n",
    "    \n",
    "    # Split cache path\n",
    "    split_cache_path = os.path.join(out_dir, f\"split_indices_seed_{split_seed}.json\")\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader, val_loader, test_loader, _split = make_loaders(\n",
    "        root=data_root,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        split_seed=split_seed,\n",
    "        split_cache_path=split_cache_path,\n",
    "        img_size=img_size,\n",
    "    )\n",
    "    \n",
    "    # Build model based on type\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_type.upper()} - Split Seed: {split_seed}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    if model_type.lower() == \"vgg19\":\n",
    "        # VGG19 model\n",
    "        model = build_vgg19_classifier(num_classes=102, freeze_features=freeze_backbone)\n",
    "        model_name = \"vgg19\"\n",
    "        \n",
    "        # Different hyperparameters for VGG19\n",
    "        if lr == 1e-4:  # Default value\n",
    "            lr = 1e-4  # Good starting point for VGG19\n",
    "        unfrozen_params = [p for p in model.model.classifier[-1].parameters()]\n",
    "        \n",
    "    elif model_type.lower() in [\"yolov5\", \"yolo\"]:\n",
    "        # YOLOv5-based model\n",
    "        model = build_yolov5_classifier(num_classes=102, freeze_backbone=freeze_backbone)\n",
    "        model_name = \"yolov5\"\n",
    "        \n",
    "        # Different hyperparameters for YOLOv5\n",
    "        if lr == 1e-4:  # Default value\n",
    "            lr = 5e-5  # Lower learning rate for YOLOv5\n",
    "        # Only train classifier parameters if backbone is frozen\n",
    "        if freeze_backbone:\n",
    "            unfrozen_params = [p for p in model.classifier.parameters()]\n",
    "        else:\n",
    "            unfrozen_params = model.parameters()\n",
    "    elif model_type.lower() in [\"yolov5_cls\", \"yolov5_real\", \"yolov5cls\"]:\n",
    "        model = build_yolov5_cls_classifier(num_classes=102, freeze_backbone=freeze_backbone)\n",
    "        model_name = \"yolov5_cls\"  # distinct label so you never misreport\n",
    "\n",
    "        if lr == 1e-4:\n",
    "            lr = 5e-5\n",
    "\n",
    "        if freeze_backbone:\n",
    "            head = model.model[-1]\n",
    "            unfrozen_params = [p for p in head.parameters()]\n",
    "        else:\n",
    "            unfrozen_params = model.parameters()\n",
    "       \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model_type: {model_type}. Choose 'vgg19' or 'yolov5'\")\n",
    "    \n",
    "    # Move model to device\n",
    "    model = model.to(device_t)\n",
    "    \n",
    "    # Print model summary\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in unfrozen_params)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"Frozen parameters: {total_params - trainable_params:,}\")\n",
    "    print(f\"Learning rate: {lr}\")\n",
    "    \n",
    "    # Define optimizer - only optimize trainable parameters\n",
    "    optimizer = optim.Adam(unfrozen_params, lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=3)\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Initialize history tracking\n",
    "    history = {\n",
    "        \"train_loss\": [], \"val_loss\": [], \"test_loss\": [],\n",
    "        \"train_acc\": [], \"val_acc\": [], \"test_acc\": [],\n",
    "        \"learning_rate\": []\n",
    "    }\n",
    "    \n",
    "    # Early stopping variables\n",
    "    best_val_acc = -1.0\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_epoch = 0\n",
    "    \n",
    "    # Checkpoint path\n",
    "    ckpt_path = os.path.join(out_dir, f\"best_{model_name}.pt\")\n",
    "    \n",
    "    # Training loop\n",
    "    print(f\"\\nStarting training for {epochs} epochs...\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Training phase\n",
    "        tr_loss, tr_acc = train_one_epoch(model, train_loader, device_t, criterion, optimizer)\n",
    "        \n",
    "        # Validation phase\n",
    "        va_loss, va_acc = evaluate(model, val_loader, device_t, criterion)\n",
    "        \n",
    "        # Test phase (for monitoring, not for early stopping)\n",
    "        te_loss, te_acc = evaluate(model, test_loader, device_t, criterion)\n",
    "        \n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step(va_loss)\n",
    "        \n",
    "        # Record history\n",
    "        history[\"train_loss\"].append(tr_loss)\n",
    "        history[\"val_loss\"].append(va_loss)\n",
    "        history[\"test_loss\"].append(te_loss)\n",
    "        history[\"train_acc\"].append(tr_acc)\n",
    "        history[\"val_acc\"].append(va_acc)\n",
    "        history[\"test_acc\"].append(te_acc)\n",
    "        history[\"learning_rate\"].append(optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        # Print progress\n",
    "        print(\n",
    "            f\"Epoch {epoch:03d}/{epochs} | \"\n",
    "            f\"Train: loss {tr_loss:.4f} acc {tr_acc:.4f} | \"\n",
    "            f\"Val: loss {va_loss:.4f} acc {va_acc:.4f} | \"\n",
    "            f\"Test: loss {te_loss:.4f} acc {te_acc:.4f} | \"\n",
    "            f\"LR: {history['learning_rate'][-1]:.2e}\"\n",
    "        )\n",
    "        \n",
    "        # Check for improvement in validation accuracy\n",
    "        if va_acc > best_val_acc:\n",
    "            best_val_acc = va_acc\n",
    "            best_val_loss = va_loss\n",
    "            best_epoch = epoch\n",
    "            epochs_no_improve = 0\n",
    "            \n",
    "            # Save best model checkpoint\n",
    "            save_checkpoint(ckpt_path, model, optimizer, epoch, best_val_acc)\n",
    "            print(f\"✓ New best model saved! Val Acc: {best_val_acc:.4f}\")\n",
    "            \n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= early_stop_patience:\n",
    "                print(f\"\\nEarly stopping triggered at epoch {epoch}. \"\n",
    "                      f\"No improvement for {early_stop_patience} epochs.\")\n",
    "                break\n",
    "        \n",
    "        # Additional: save checkpoint every 5 epochs\n",
    "        if epoch % 5 == 0 and epoch != best_epoch:\n",
    "            intermediate_ckpt = os.path.join(out_dir, f\"{model_name}_epoch_{epoch}.pt\")\n",
    "            save_checkpoint(intermediate_ckpt, model, optimizer, epoch, va_acc)\n",
    "    \n",
    "    # Final evaluation on test set with best model\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL EVALUATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load best model\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device_t)\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    final_test_loss, final_test_acc = evaluate(model, test_loader, device_t, criterion)\n",
    "    \n",
    "    # Save training curves\n",
    "    save_curves(out_dir, history, model_name=model_name)\n",
    "    \n",
    "    # Save full history\n",
    "    history_path = os.path.join(out_dir, f\"history_{model_name}.json\")\n",
    "    with open(history_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({k: [float(v) for v in vals] for k, vals in history.items()}, f, indent=2)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{model_name.upper()} TRAINING SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Data split seed: {split_seed}\")\n",
    "    print(f\"Best epoch: {best_epoch}\")\n",
    "    print(f\"Best validation accuracy: {best_val_acc:.4f}\")\n",
    "    print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "    print(f\"Final test accuracy: {final_test_acc:.4f}\")\n",
    "    print(f\"Final test loss: {final_test_loss:.4f}\")\n",
    "    print(f\"Total epochs trained: {len(history['train_acc'])}\")\n",
    "    \n",
    "    \n",
    "    print(f\"\\nSaved files:\")\n",
    "    print(f\"- Checkpoint: {ckpt_path}\")\n",
    "    print(f\"- Accuracy curve: {os.path.join(out_dir, f'accuracy_{model_name}.png')}\")\n",
    "    print(f\"- Loss curve: {os.path.join(out_dir, f'loss_{model_name}.png')}\")\n",
    "    print(f\"- History: {history_path}\")\n",
    "    print(f\"- Split indices: {split_cache_path}\")\n",
    "    \n",
    "    # Add final test metrics to history\n",
    "    history[\"final_test_acc\"] = final_test_acc\n",
    "    history[\"final_test_loss\"] = final_test_loss\n",
    "    history[\"best_val_acc\"] = best_val_acc\n",
    "    history[\"best_epoch\"] = best_epoch\n",
    "    history[\"model_type\"] = model_name\n",
    "    history[\"split_seed\"] = split_seed\n",
    "    \n",
    "    return history, ckpt_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6481fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Modified save_curves to support both models\n",
    "def save_curves(out_dir: str, history: Dict[str, List[float]], model_name: str = \"model\") -> None:\n",
    "    \"\"\"\n",
    "    Save accuracy and loss curves for the model.\n",
    "    \"\"\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history[\"train_acc\"], label=\"Train\", linewidth=2)\n",
    "    plt.plot(history[\"val_acc\"], label=\"Validation\", linewidth=2)\n",
    "    plt.plot(history[\"test_acc\"], label=\"Test\", linewidth=2)\n",
    "    plt.axhline(y=0.70, color='gray', linestyle='--', alpha=0.7, label='70% Requirement')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"{model_name.upper()} - Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history[\"train_loss\"], label=\"Train\", linewidth=2)\n",
    "    plt.plot(history[\"val_loss\"], label=\"Validation\", linewidth=2)\n",
    "    plt.plot(history[\"test_loss\"], label=\"Test\", linewidth=2)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Cross-Entropy Loss\")\n",
    "    plt.title(f\"{model_name.upper()} - Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, f\"training_curves_{model_name}.png\"), dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Learning rate plot\n",
    "    if \"learning_rate\" in history:\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.plot(history[\"learning_rate\"], linewidth=2)\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Learning Rate\")\n",
    "        plt.title(f\"{model_name.upper()} - Learning Rate Schedule\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(out_dir, f\"learning_rate_{model_name}.png\"), dpi=150, bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a76888dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # Determinism (can reduce speed; )\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0bb88ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/35 | train loss 3.1448 acc 0.2865 | val loss 1.5717 acc 0.6116 | test loss 1.6156 acc 0.6099\n",
      "Epoch 002/35 | train loss 1.3604 acc 0.6412 | val loss 0.9499 acc 0.7538 | test loss 0.9626 acc 0.7480\n",
      "Epoch 003/35 | train loss 0.8579 acc 0.7587 | val loss 0.7738 acc 0.7831 | test loss 0.7844 acc 0.7871\n",
      "Epoch 004/35 | train loss 0.6324 acc 0.8190 | val loss 0.6457 acc 0.8217 | test loss 0.6614 acc 0.8193\n",
      "Epoch 005/35 | train loss 0.4731 acc 0.8625 | val loss 0.6027 acc 0.8334 | test loss 0.6209 acc 0.8330\n",
      "Epoch 006/35 | train loss 0.3598 acc 0.8898 | val loss 0.5875 acc 0.8315 | test loss 0.6244 acc 0.8384\n",
      "Epoch 007/35 | train loss 0.3036 acc 0.9108 | val loss 0.5879 acc 0.8344 | test loss 0.6061 acc 0.8364\n",
      "Epoch 008/35 | train loss 0.2374 acc 0.9287 | val loss 0.5396 acc 0.8520 | test loss 0.5580 acc 0.8540\n",
      "Epoch 009/35 | train loss 0.2295 acc 0.9304 | val loss 0.5612 acc 0.8447 | test loss 0.5477 acc 0.8579\n",
      "Epoch 010/35 | train loss 0.1890 acc 0.9436 | val loss 0.5072 acc 0.8500 | test loss 0.5317 acc 0.8521\n",
      "Epoch 011/35 | train loss 0.1515 acc 0.9555 | val loss 0.5295 acc 0.8549 | test loss 0.5339 acc 0.8657\n",
      "Epoch 012/35 | train loss 0.1302 acc 0.9617 | val loss 0.5341 acc 0.8539 | test loss 0.5575 acc 0.8599\n",
      "Epoch 013/35 | train loss 0.1241 acc 0.9619 | val loss 0.5429 acc 0.8544 | test loss 0.5619 acc 0.8540\n",
      "Epoch 014/35 | train loss 0.1116 acc 0.9651 | val loss 0.5485 acc 0.8534 | test loss 0.5832 acc 0.8491\n",
      "Epoch 015/35 | train loss 0.0910 acc 0.9736 | val loss 0.5320 acc 0.8622 | test loss 0.5332 acc 0.8608\n",
      "Epoch 016/35 | train loss 0.0937 acc 0.9722 | val loss 0.5345 acc 0.8578 | test loss 0.5502 acc 0.8662\n",
      "Epoch 017/35 | train loss 0.0690 acc 0.9805 | val loss 0.5832 acc 0.8608 | test loss 0.6090 acc 0.8491\n",
      "Early stopping triggered (patience=7).\n",
      "\n",
      "Summary\n",
      "- Split seed: 1\n",
      "- Best val acc: 0.8622 (epoch 15)\n",
      "- Last test acc: 0.8491\n",
      "- Saved: ./results/vgg19_seed1\\accuracy_vgg19.png\n",
      "- Saved: ./results/vgg19_seed1\\loss_vgg19.png\n",
      "- Checkpoint: ./results/vgg19_seed1\\best_vgg19.pt\n",
      "- Split indices: ./results/vgg19_seed1\\split_indices_seed_1.json\n"
     ]
    }
   ],
   "source": [
    "h1, ckpt1 = run_experiment(\n",
    "    data_root=r\"C:\\Users\\hp\\Downloads\\102flowers\",\n",
    "    split_seed=1,\n",
    "    out_dir=\"./results/vgg19_seed1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9634ef89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/35 | train loss 3.1209 acc 0.2985 | val loss 1.5443 acc 0.6082 | test loss 1.4719 acc 0.6323\n",
      "Epoch 002/35 | train loss 1.3546 acc 0.6290 | val loss 0.9866 acc 0.7479 | test loss 0.9165 acc 0.7559\n",
      "Epoch 003/35 | train loss 0.8602 acc 0.7653 | val loss 0.8094 acc 0.7816 | test loss 0.7834 acc 0.7856\n",
      "Epoch 004/35 | train loss 0.6295 acc 0.8227 | val loss 0.7129 acc 0.8046 | test loss 0.6548 acc 0.8174\n",
      "Epoch 005/35 | train loss 0.4379 acc 0.8708 | val loss 0.6384 acc 0.8241 | test loss 0.5684 acc 0.8403\n",
      "Epoch 006/35 | train loss 0.3623 acc 0.8896 | val loss 0.6342 acc 0.8295 | test loss 0.5392 acc 0.8550\n",
      "Epoch 007/35 | train loss 0.3023 acc 0.9135 | val loss 0.6117 acc 0.8349 | test loss 0.5510 acc 0.8452\n",
      "Epoch 008/35 | train loss 0.2088 acc 0.9387 | val loss 0.5598 acc 0.8549 | test loss 0.4834 acc 0.8662\n",
      "Epoch 009/35 | train loss 0.2258 acc 0.9255 | val loss 0.6057 acc 0.8398 | test loss 0.5124 acc 0.8540\n",
      "Epoch 010/35 | train loss 0.1719 acc 0.9489 | val loss 0.5469 acc 0.8534 | test loss 0.4875 acc 0.8682\n",
      "Epoch 011/35 | train loss 0.1597 acc 0.9538 | val loss 0.5994 acc 0.8359 | test loss 0.5222 acc 0.8604\n",
      "Epoch 012/35 | train loss 0.1320 acc 0.9599 | val loss 0.6039 acc 0.8427 | test loss 0.5061 acc 0.8652\n",
      "Epoch 013/35 | train loss 0.1417 acc 0.9585 | val loss 0.5762 acc 0.8466 | test loss 0.4747 acc 0.8721\n",
      "Epoch 014/35 | train loss 0.1116 acc 0.9636 | val loss 0.5878 acc 0.8490 | test loss 0.4961 acc 0.8716\n",
      "Epoch 015/35 | train loss 0.0945 acc 0.9700 | val loss 0.5935 acc 0.8534 | test loss 0.5021 acc 0.8643\n",
      "Epoch 016/35 | train loss 0.0924 acc 0.9712 | val loss 0.6607 acc 0.8383 | test loss 0.5467 acc 0.8608\n",
      "Epoch 017/35 | train loss 0.0835 acc 0.9773 | val loss 0.6491 acc 0.8383 | test loss 0.5522 acc 0.8555\n",
      "Early stopping triggered (patience=7).\n",
      "\n",
      "Summary\n",
      "- Split seed: 2\n",
      "- Best val acc: 0.8549 (epoch 8)\n",
      "- Last test acc: 0.8555\n",
      "- Saved: ./results/vgg19_seed2\\accuracy_vgg19.png\n",
      "- Saved: ./results/vgg19_seed2\\loss_vgg19.png\n",
      "- Checkpoint: ./results/vgg19_seed2\\best_vgg19.pt\n",
      "- Split indices: ./results/vgg19_seed2\\split_indices_seed_2.json\n"
     ]
    }
   ],
   "source": [
    "h2, ckpt2 = run_experiment(\n",
    "    data_root=r\"C:\\Users\\hp\\Downloads\\102flowers\",\n",
    "    split_seed=2,\n",
    "    out_dir=\"./results/vgg19_seed2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813b4ef3",
   "metadata": {},
   "source": [
    "### YOLOv5 Implementation Challenge:\n",
    "Attempted to use YOLOv5, but encountered compatibility issues \n",
    "with the object detection architecture for classification tasks. As an \n",
    "alternative, used MobileNetV3 with a similar transfer learning approach. \n",
    "This maintains the spirit of using a modern, efficient CNN architecture.\n",
    "\n",
    "**Results labeled as \"YOLOv5\" in outputs are actually MobileNetV3.**\n",
    "needs reimplementation of YOLOv5 classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b42530c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== YOLOv5 Experiments ===\n",
      "\n",
      "============================================================\n",
      "Training YOLOV5 - Split Seed: 1\n",
      "============================================================\n",
      "Loading YOLOv5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2026-1-14 Python-3.13.5 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load YOLOv5: 'DetectionModel' object is not subscriptable\n",
      "Falling back to MobileNetV3 as alternative\n",
      "Model: yolov5\n",
      "Total parameters: 1,622,406\n",
      "Trainable parameters: 695,398\n",
      "Frozen parameters: 927,008\n",
      "Learning rate: 5e-05\n",
      "\n",
      "Starting training for 30 epochs...\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 001/30 | Train: loss 4.5433 acc 0.0344 | Val: loss 4.3629 acc 0.0850 | Test: loss 4.3896 acc 0.0625 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.0850\n",
      "Epoch 002/30 | Train: loss 4.2730 acc 0.1488 | Val: loss 4.0968 acc 0.2711 | Test: loss 4.1223 acc 0.2534 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.2711\n",
      "Epoch 003/30 | Train: loss 4.0178 acc 0.3036 | Val: loss 3.8545 acc 0.4055 | Test: loss 3.8832 acc 0.3872 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.4055\n",
      "Epoch 004/30 | Train: loss 3.7717 acc 0.4394 | Val: loss 3.6246 acc 0.4836 | Test: loss 3.6572 acc 0.4658 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.4836\n",
      "Epoch 005/30 | Train: loss 3.5384 acc 0.5244 | Val: loss 3.4009 acc 0.5354 | Test: loss 3.4368 acc 0.5239 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.5354\n",
      "Epoch 006/30 | Train: loss 3.3257 acc 0.5691 | Val: loss 3.1949 acc 0.5677 | Test: loss 3.2342 acc 0.5610 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.5677\n",
      "Epoch 007/30 | Train: loss 3.1306 acc 0.6155 | Val: loss 3.0039 acc 0.5960 | Test: loss 3.0445 acc 0.5908 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.5960\n",
      "Epoch 008/30 | Train: loss 2.9407 acc 0.6424 | Val: loss 2.8293 acc 0.6180 | Test: loss 2.8713 acc 0.6118 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.6180\n",
      "Epoch 009/30 | Train: loss 2.7605 acc 0.6693 | Val: loss 2.6720 acc 0.6326 | Test: loss 2.7135 acc 0.6348 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.6326\n",
      "Epoch 010/30 | Train: loss 2.6126 acc 0.6895 | Val: loss 2.5245 acc 0.6468 | Test: loss 2.5656 acc 0.6543 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.6468\n",
      "Epoch 011/30 | Train: loss 2.4589 acc 0.7130 | Val: loss 2.3962 acc 0.6571 | Test: loss 2.4357 acc 0.6646 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.6571\n",
      "Epoch 012/30 | Train: loss 2.3331 acc 0.7262 | Val: loss 2.2754 acc 0.6668 | Test: loss 2.3134 acc 0.6802 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.6668\n",
      "Epoch 013/30 | Train: loss 2.2027 acc 0.7421 | Val: loss 2.1644 acc 0.6751 | Test: loss 2.1997 acc 0.6909 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.6751\n",
      "Epoch 014/30 | Train: loss 2.0875 acc 0.7509 | Val: loss 2.0640 acc 0.6893 | Test: loss 2.0960 acc 0.7007 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.6893\n",
      "Epoch 015/30 | Train: loss 1.9992 acc 0.7582 | Val: loss 1.9690 acc 0.6981 | Test: loss 1.9984 acc 0.7114 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.6981\n",
      "Epoch 016/30 | Train: loss 1.8951 acc 0.7692 | Val: loss 1.8830 acc 0.7079 | Test: loss 1.9094 acc 0.7236 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7079\n",
      "Epoch 017/30 | Train: loss 1.8050 acc 0.7785 | Val: loss 1.8043 acc 0.7181 | Test: loss 1.8284 acc 0.7310 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7181\n",
      "Epoch 018/30 | Train: loss 1.7214 acc 0.7880 | Val: loss 1.7345 acc 0.7323 | Test: loss 1.7550 acc 0.7451 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7323\n",
      "Epoch 019/30 | Train: loss 1.6457 acc 0.8019 | Val: loss 1.6665 acc 0.7367 | Test: loss 1.6851 acc 0.7480 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7367\n",
      "Epoch 020/30 | Train: loss 1.5837 acc 0.8014 | Val: loss 1.6098 acc 0.7460 | Test: loss 1.6263 acc 0.7568 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7460\n",
      "Epoch 021/30 | Train: loss 1.5125 acc 0.8149 | Val: loss 1.5484 acc 0.7533 | Test: loss 1.5619 acc 0.7666 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7533\n",
      "Epoch 022/30 | Train: loss 1.4536 acc 0.8188 | Val: loss 1.4956 acc 0.7601 | Test: loss 1.5067 acc 0.7720 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7601\n",
      "Epoch 023/30 | Train: loss 1.3948 acc 0.8234 | Val: loss 1.4453 acc 0.7689 | Test: loss 1.4542 acc 0.7769 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7689\n",
      "Epoch 024/30 | Train: loss 1.3433 acc 0.8300 | Val: loss 1.4005 acc 0.7763 | Test: loss 1.4071 acc 0.7842 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7763\n",
      "Epoch 025/30 | Train: loss 1.3111 acc 0.8300 | Val: loss 1.3572 acc 0.7792 | Test: loss 1.3618 acc 0.7871 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7792\n",
      "Epoch 026/30 | Train: loss 1.2589 acc 0.8371 | Val: loss 1.3182 acc 0.7846 | Test: loss 1.3212 acc 0.7969 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7846\n",
      "Epoch 027/30 | Train: loss 1.2099 acc 0.8439 | Val: loss 1.2818 acc 0.7904 | Test: loss 1.2839 acc 0.8022 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7904\n",
      "Epoch 028/30 | Train: loss 1.1655 acc 0.8476 | Val: loss 1.2400 acc 0.7934 | Test: loss 1.2409 acc 0.8062 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7934\n",
      "Epoch 029/30 | Train: loss 1.1311 acc 0.8581 | Val: loss 1.2081 acc 0.7987 | Test: loss 1.2081 acc 0.8105 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7987\n",
      "Epoch 030/30 | Train: loss 1.0951 acc 0.8591 | Val: loss 1.1784 acc 0.8041 | Test: loss 1.1770 acc 0.8135 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8041\n",
      "\n",
      "============================================================\n",
      "FINAL EVALUATION\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "YOLOV5 TRAINING SUMMARY\n",
      "============================================================\n",
      "Data split seed: 1\n",
      "Best epoch: 30\n",
      "Best validation accuracy: 0.8041\n",
      "Best validation loss: 1.1784\n",
      "Final test accuracy: 0.8135\n",
      "Final test loss: 1.1770\n",
      "Total epochs trained: 30\n",
      "\n",
      "70% accuracy requirement: 81.35% (✓ EXCEEDS)\n",
      "\n",
      "Saved files:\n",
      "- Checkpoint: ./results/yolov5_seed1\\best_yolov5.pt\n",
      "- Accuracy curve: ./results/yolov5_seed1\\accuracy_yolov5.png\n",
      "- Loss curve: ./results/yolov5_seed1\\loss_yolov5.png\n",
      "- History: ./results/yolov5_seed1\\history_yolov5.json\n",
      "- Split indices: ./results/yolov5_seed1\\split_indices_seed_1.json\n"
     ]
    }
   ],
   "source": [
    "# Run YOLOv5 experiments\n",
    "print(\"\\n=== YOLOv5 Experiments ===\")\n",
    "h1_yolo, ckpt1_yolo = run_experiment(\n",
    "    model_type=\"yolov5\",\n",
    "    data_root=r\"C:\\Users\\hp\\Downloads\\102flowers\",\n",
    "    split_seed=1,\n",
    "    out_dir=\"./results/yolov5_seed1\",\n",
    "    epochs=30,\n",
    "    lr=5e-5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c04d049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training YOLOV5 - Split Seed: 2\n",
      "============================================================\n",
      "Loading YOLOv5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2026-1-14 Python-3.13.5 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load YOLOv5: 'DetectionModel' object is not subscriptable\n",
      "Falling back to MobileNetV3 as alternative\n",
      "Model: yolov5\n",
      "Total parameters: 1,622,406\n",
      "Trainable parameters: 695,398\n",
      "Frozen parameters: 927,008\n",
      "Learning rate: 5e-05\n",
      "\n",
      "Starting training for 30 epochs...\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 001/30 | Train: loss 4.5433 acc 0.0330 | Val: loss 4.3890 acc 0.0816 | Test: loss 4.3883 acc 0.0859 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.0816\n",
      "Epoch 002/30 | Train: loss 4.2739 acc 0.1431 | Val: loss 4.1246 acc 0.2565 | Test: loss 4.1204 acc 0.2627 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.2565\n",
      "Epoch 003/30 | Train: loss 4.0213 acc 0.2978 | Val: loss 3.8868 acc 0.3928 | Test: loss 3.8778 acc 0.4009 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.3928\n",
      "Epoch 004/30 | Train: loss 3.7787 acc 0.4231 | Val: loss 3.6612 acc 0.4846 | Test: loss 3.6474 acc 0.4893 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.4846\n",
      "Epoch 005/30 | Train: loss 3.5451 acc 0.5181 | Val: loss 3.4427 acc 0.5344 | Test: loss 3.4255 acc 0.5405 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.5344\n",
      "Epoch 006/30 | Train: loss 3.3362 acc 0.5601 | Val: loss 3.2402 acc 0.5701 | Test: loss 3.2204 acc 0.5796 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.5701\n",
      "Epoch 007/30 | Train: loss 3.1430 acc 0.5997 | Val: loss 3.0518 acc 0.5975 | Test: loss 3.0274 acc 0.6050 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.5975\n",
      "Epoch 008/30 | Train: loss 2.9609 acc 0.6343 | Val: loss 2.8762 acc 0.6209 | Test: loss 2.8495 acc 0.6270 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.6209\n",
      "Epoch 009/30 | Train: loss 2.7767 acc 0.6575 | Val: loss 2.7148 acc 0.6409 | Test: loss 2.6865 acc 0.6460 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.6409\n",
      "Epoch 010/30 | Train: loss 2.6313 acc 0.6724 | Val: loss 2.5722 acc 0.6551 | Test: loss 2.5408 acc 0.6611 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.6551\n",
      "Epoch 011/30 | Train: loss 2.4824 acc 0.6869 | Val: loss 2.4384 acc 0.6702 | Test: loss 2.4054 acc 0.6753 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.6702\n",
      "Epoch 012/30 | Train: loss 2.3527 acc 0.7171 | Val: loss 2.3157 acc 0.6844 | Test: loss 2.2811 acc 0.6855 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.6844\n",
      "Epoch 013/30 | Train: loss 2.2333 acc 0.7284 | Val: loss 2.2059 acc 0.6917 | Test: loss 2.1707 acc 0.6992 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.6917\n",
      "Epoch 014/30 | Train: loss 2.1347 acc 0.7384 | Val: loss 2.0987 acc 0.7025 | Test: loss 2.0628 acc 0.7095 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7025\n",
      "Epoch 015/30 | Train: loss 2.0137 acc 0.7609 | Val: loss 2.0071 acc 0.7074 | Test: loss 1.9707 acc 0.7227 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7074\n",
      "Epoch 016/30 | Train: loss 1.9198 acc 0.7741 | Val: loss 1.9189 acc 0.7142 | Test: loss 1.8816 acc 0.7363 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7142\n",
      "Epoch 017/30 | Train: loss 1.8317 acc 0.7799 | Val: loss 1.8334 acc 0.7220 | Test: loss 1.7959 acc 0.7480 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7220\n",
      "Epoch 018/30 | Train: loss 1.7580 acc 0.7814 | Val: loss 1.7594 acc 0.7298 | Test: loss 1.7219 acc 0.7520 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7298\n",
      "Epoch 019/30 | Train: loss 1.6715 acc 0.7914 | Val: loss 1.6952 acc 0.7391 | Test: loss 1.6570 acc 0.7593 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7391\n",
      "Epoch 020/30 | Train: loss 1.6067 acc 0.8012 | Val: loss 1.6292 acc 0.7430 | Test: loss 1.5902 acc 0.7651 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7430\n",
      "Epoch 021/30 | Train: loss 1.5363 acc 0.8166 | Val: loss 1.5752 acc 0.7513 | Test: loss 1.5359 acc 0.7739 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7513\n",
      "Epoch 022/30 | Train: loss 1.4944 acc 0.8112 | Val: loss 1.5146 acc 0.7616 | Test: loss 1.4750 acc 0.7847 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7616\n",
      "Epoch 023/30 | Train: loss 1.4191 acc 0.8337 | Val: loss 1.4619 acc 0.7699 | Test: loss 1.4232 acc 0.7891 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7699\n",
      "Epoch 024/30 | Train: loss 1.3742 acc 0.8317 | Val: loss 1.4134 acc 0.7753 | Test: loss 1.3744 acc 0.7969 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7753\n",
      "Epoch 025/30 | Train: loss 1.3198 acc 0.8432 | Val: loss 1.3722 acc 0.7821 | Test: loss 1.3331 acc 0.8032 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7821\n",
      "Epoch 026/30 | Train: loss 1.2663 acc 0.8495 | Val: loss 1.3328 acc 0.7890 | Test: loss 1.2937 acc 0.8076 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7890\n",
      "Epoch 027/30 | Train: loss 1.2308 acc 0.8442 | Val: loss 1.2908 acc 0.7953 | Test: loss 1.2513 acc 0.8135 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7953\n",
      "Epoch 028/30 | Train: loss 1.1986 acc 0.8498 | Val: loss 1.2546 acc 0.7987 | Test: loss 1.2155 acc 0.8174 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7987\n",
      "Epoch 029/30 | Train: loss 1.1480 acc 0.8549 | Val: loss 1.2224 acc 0.8007 | Test: loss 1.1833 acc 0.8208 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8007\n",
      "Epoch 030/30 | Train: loss 1.1199 acc 0.8549 | Val: loss 1.1948 acc 0.8012 | Test: loss 1.1546 acc 0.8223 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8012\n",
      "\n",
      "============================================================\n",
      "FINAL EVALUATION\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "YOLOV5 TRAINING SUMMARY\n",
      "============================================================\n",
      "Data split seed: 2\n",
      "Best epoch: 30\n",
      "Best validation accuracy: 0.8012\n",
      "Best validation loss: 1.1948\n",
      "Final test accuracy: 0.8223\n",
      "Final test loss: 1.1546\n",
      "Total epochs trained: 30\n",
      "\n",
      "70% accuracy requirement: 82.23% (✓ EXCEEDS)\n",
      "\n",
      "Saved files:\n",
      "- Checkpoint: ./results/yolov5_seed2\\best_yolov5.pt\n",
      "- Accuracy curve: ./results/yolov5_seed2\\accuracy_yolov5.png\n",
      "- Loss curve: ./results/yolov5_seed2\\loss_yolov5.png\n",
      "- History: ./results/yolov5_seed2\\history_yolov5.json\n",
      "- Split indices: ./results/yolov5_seed2\\split_indices_seed_2.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "h2_yolo, ckpt2_yolo = run_experiment(\n",
    "    model_type=\"yolov5\",\n",
    "    data_root=r\"C:\\Users\\hp\\Downloads\\102flowers\",\n",
    "    split_seed=2,\n",
    "    out_dir=\"./results/yolov5_seed2\",\n",
    "    epochs=30,\n",
    "    lr=5e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2810fe",
   "metadata": {},
   "source": [
    "Yolov5 fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "061175e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== REAL YOLOv5-CLS Experiments ===\n",
      "\n",
      "============================================================\n",
      "Training YOLOV5_CLS - Split Seed: 1\n",
      "============================================================\n",
      "Loading REAL YOLOv5-CLS checkpoint: yolov5s-cls.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2026-1-14 Python-3.13.5 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s-cls.pt to yolov5s-cls.pt...\n",
      "100%|██████████| 10.5M/10.5M [00:05<00:00, 1.96MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: yolov5_cls\n",
      "Total parameters: 4,303,142\n",
      "Trainable parameters: 788,582\n",
      "Frozen parameters: 3,514,560\n",
      "Learning rate: 5e-05\n",
      "\n",
      "Starting training for 30 epochs...\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 001/30 | Train: loss 4.2718 acc 0.1063 | Val: loss 3.8966 acc 0.2428 | Test: loss 3.9262 acc 0.2139 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.2428\n",
      "Epoch 002/30 | Train: loss 3.5577 acc 0.3136 | Val: loss 3.2747 acc 0.3884 | Test: loss 3.3098 acc 0.3711 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.3884\n",
      "Epoch 003/30 | Train: loss 2.9450 acc 0.4934 | Val: loss 2.7561 acc 0.5032 | Test: loss 2.7872 acc 0.5015 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.5032\n",
      "Epoch 004/30 | Train: loss 2.4163 acc 0.6087 | Val: loss 2.3015 acc 0.6185 | Test: loss 2.3276 acc 0.6265 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.6185\n",
      "Epoch 005/30 | Train: loss 1.9961 acc 0.7171 | Val: loss 1.9385 acc 0.6790 | Test: loss 1.9541 acc 0.6909 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.6790\n",
      "Epoch 006/30 | Train: loss 1.6719 acc 0.7587 | Val: loss 1.6967 acc 0.7279 | Test: loss 1.7053 acc 0.7383 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7279\n",
      "Epoch 007/30 | Train: loss 1.4243 acc 0.8085 | Val: loss 1.4675 acc 0.7645 | Test: loss 1.4765 acc 0.7744 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7645\n",
      "Epoch 008/30 | Train: loss 1.2315 acc 0.8339 | Val: loss 1.3176 acc 0.7846 | Test: loss 1.3201 acc 0.7979 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7846\n",
      "Epoch 009/30 | Train: loss 1.0767 acc 0.8596 | Val: loss 1.1645 acc 0.8105 | Test: loss 1.1617 acc 0.8169 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8105\n",
      "Epoch 010/30 | Train: loss 0.9539 acc 0.8713 | Val: loss 1.0575 acc 0.8300 | Test: loss 1.0546 acc 0.8325 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8300\n",
      "Epoch 011/30 | Train: loss 0.8462 acc 0.8937 | Val: loss 0.9725 acc 0.8456 | Test: loss 0.9676 acc 0.8408 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8456\n",
      "Epoch 012/30 | Train: loss 0.7709 acc 0.9013 | Val: loss 0.8952 acc 0.8564 | Test: loss 0.8886 acc 0.8530 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8564\n",
      "Epoch 013/30 | Train: loss 0.6986 acc 0.9064 | Val: loss 0.8335 acc 0.8661 | Test: loss 0.8283 acc 0.8652 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8661\n",
      "Epoch 014/30 | Train: loss 0.6446 acc 0.9155 | Val: loss 0.7658 acc 0.8764 | Test: loss 0.7561 acc 0.8765 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8764\n",
      "Epoch 015/30 | Train: loss 0.6000 acc 0.9201 | Val: loss 0.7384 acc 0.8784 | Test: loss 0.7305 acc 0.8770 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8784\n",
      "Epoch 016/30 | Train: loss 0.5568 acc 0.9284 | Val: loss 0.6968 acc 0.8842 | Test: loss 0.6890 acc 0.8818 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8842\n",
      "Epoch 017/30 | Train: loss 0.5106 acc 0.9350 | Val: loss 0.6608 acc 0.8896 | Test: loss 0.6531 acc 0.8862 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8896\n",
      "Epoch 018/30 | Train: loss 0.4736 acc 0.9406 | Val: loss 0.6212 acc 0.8920 | Test: loss 0.6105 acc 0.8911 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8920\n",
      "Epoch 019/30 | Train: loss 0.4407 acc 0.9450 | Val: loss 0.5939 acc 0.8959 | Test: loss 0.5854 acc 0.8970 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8959\n",
      "Epoch 020/30 | Train: loss 0.4138 acc 0.9465 | Val: loss 0.5648 acc 0.8994 | Test: loss 0.5571 acc 0.8960 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8994\n",
      "Epoch 021/30 | Train: loss 0.3920 acc 0.9487 | Val: loss 0.5533 acc 0.9008 | Test: loss 0.5444 acc 0.8994 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9008\n",
      "Epoch 022/30 | Train: loss 0.3626 acc 0.9533 | Val: loss 0.5252 acc 0.9038 | Test: loss 0.5155 acc 0.9048 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9038\n",
      "Epoch 023/30 | Train: loss 0.3469 acc 0.9565 | Val: loss 0.4990 acc 0.9067 | Test: loss 0.4905 acc 0.9106 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9067\n",
      "Epoch 024/30 | Train: loss 0.3258 acc 0.9558 | Val: loss 0.4898 acc 0.9052 | Test: loss 0.4810 acc 0.9077 | LR: 5.00e-05\n",
      "Epoch 025/30 | Train: loss 0.3127 acc 0.9619 | Val: loss 0.4684 acc 0.9126 | Test: loss 0.4590 acc 0.9160 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9126\n",
      "Epoch 026/30 | Train: loss 0.2839 acc 0.9658 | Val: loss 0.4510 acc 0.9101 | Test: loss 0.4396 acc 0.9165 | LR: 5.00e-05\n",
      "Epoch 027/30 | Train: loss 0.2789 acc 0.9643 | Val: loss 0.4504 acc 0.9106 | Test: loss 0.4408 acc 0.9141 | LR: 5.00e-05\n",
      "Epoch 028/30 | Train: loss 0.2642 acc 0.9685 | Val: loss 0.4269 acc 0.9155 | Test: loss 0.4181 acc 0.9219 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9155\n",
      "Epoch 029/30 | Train: loss 0.2540 acc 0.9692 | Val: loss 0.4188 acc 0.9160 | Test: loss 0.4089 acc 0.9258 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9160\n",
      "Epoch 030/30 | Train: loss 0.2407 acc 0.9675 | Val: loss 0.3983 acc 0.9184 | Test: loss 0.3863 acc 0.9277 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9184\n",
      "\n",
      "============================================================\n",
      "FINAL EVALUATION\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "YOLOV5_CLS TRAINING SUMMARY\n",
      "============================================================\n",
      "Data split seed: 1\n",
      "Best epoch: 30\n",
      "Best validation accuracy: 0.9184\n",
      "Best validation loss: 0.3983\n",
      "Final test accuracy: 0.9277\n",
      "Final test loss: 0.3863\n",
      "Total epochs trained: 30\n",
      "\n",
      "Saved files:\n",
      "- Checkpoint: ./results/yolov5_cls_seed1\\best_yolov5_cls.pt\n",
      "- Accuracy curve: ./results/yolov5_cls_seed1\\accuracy_yolov5_cls.png\n",
      "- Loss curve: ./results/yolov5_cls_seed1\\loss_yolov5_cls.png\n",
      "- History: ./results/yolov5_cls_seed1\\history_yolov5_cls.json\n",
      "- Split indices: ./results/yolov5_cls_seed1\\split_indices_seed_1.json\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== REAL YOLOv5-CLS Experiments ===\")\n",
    "\n",
    "h1_yolo_real, ckpt1_yolo_real = run_experiment(\n",
    "    model_type=\"yolov5_cls\",\n",
    "    data_root=r\"C:\\Users\\hp\\Downloads\\102flowers\",\n",
    "    split_seed=1,\n",
    "    out_dir=\"./results/yolov5_cls_seed1\",\n",
    "    epochs=30,\n",
    "    lr=5e-5,\n",
    "    freeze_backbone=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78160f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training YOLOV5_CLS - Split Seed: 2\n",
      "============================================================\n",
      "Loading REAL YOLOv5-CLS checkpoint: yolov5s-cls.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2026-1-14 Python-3.13.5 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: yolov5_cls\n",
      "Total parameters: 4,303,142\n",
      "Trainable parameters: 788,582\n",
      "Frozen parameters: 3,514,560\n",
      "Learning rate: 5e-05\n",
      "\n",
      "Starting training for 30 epochs...\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 001/30 | Train: loss 4.2770 acc 0.1295 | Val: loss 3.9111 acc 0.2296 | Test: loss 3.8800 acc 0.2515 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.2296\n",
      "Epoch 002/30 | Train: loss 3.5514 acc 0.3129 | Val: loss 3.3129 acc 0.3810 | Test: loss 3.2716 acc 0.4111 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.3810\n",
      "Epoch 003/30 | Train: loss 2.9393 acc 0.5000 | Val: loss 2.7868 acc 0.5056 | Test: loss 2.7405 acc 0.5215 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.5056\n",
      "Epoch 004/30 | Train: loss 2.4117 acc 0.6241 | Val: loss 2.3262 acc 0.6014 | Test: loss 2.2819 acc 0.6147 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.6014\n",
      "Epoch 005/30 | Train: loss 2.0022 acc 0.6971 | Val: loss 1.9736 acc 0.6781 | Test: loss 1.9328 acc 0.6880 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.6781\n",
      "Epoch 006/30 | Train: loss 1.6827 acc 0.7567 | Val: loss 1.7105 acc 0.7206 | Test: loss 1.6722 acc 0.7300 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7206\n",
      "Epoch 007/30 | Train: loss 1.4280 acc 0.8136 | Val: loss 1.4938 acc 0.7660 | Test: loss 1.4555 acc 0.7710 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7660\n",
      "Epoch 008/30 | Train: loss 1.2319 acc 0.8395 | Val: loss 1.3309 acc 0.7914 | Test: loss 1.2923 acc 0.8042 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7914\n",
      "Epoch 009/30 | Train: loss 1.0778 acc 0.8679 | Val: loss 1.1923 acc 0.8129 | Test: loss 1.1545 acc 0.8257 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8129\n",
      "Epoch 010/30 | Train: loss 0.9691 acc 0.8757 | Val: loss 1.0897 acc 0.8173 | Test: loss 1.0509 acc 0.8389 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8173\n",
      "Epoch 011/30 | Train: loss 0.8568 acc 0.8901 | Val: loss 0.9885 acc 0.8334 | Test: loss 0.9508 acc 0.8457 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8334\n",
      "Epoch 012/30 | Train: loss 0.7707 acc 0.9035 | Val: loss 0.9252 acc 0.8422 | Test: loss 0.8867 acc 0.8618 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8422\n",
      "Epoch 013/30 | Train: loss 0.7060 acc 0.9067 | Val: loss 0.8447 acc 0.8530 | Test: loss 0.8058 acc 0.8691 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8530\n",
      "Epoch 014/30 | Train: loss 0.6482 acc 0.9174 | Val: loss 0.8029 acc 0.8627 | Test: loss 0.7626 acc 0.8794 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8627\n",
      "Epoch 015/30 | Train: loss 0.6034 acc 0.9179 | Val: loss 0.7514 acc 0.8691 | Test: loss 0.7115 acc 0.8804 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8691\n",
      "Epoch 016/30 | Train: loss 0.5603 acc 0.9216 | Val: loss 0.7099 acc 0.8774 | Test: loss 0.6736 acc 0.8882 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8774\n",
      "Epoch 017/30 | Train: loss 0.5084 acc 0.9336 | Val: loss 0.6817 acc 0.8808 | Test: loss 0.6422 acc 0.8887 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8808\n",
      "Epoch 018/30 | Train: loss 0.4777 acc 0.9389 | Val: loss 0.6331 acc 0.8911 | Test: loss 0.5960 acc 0.8955 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8911\n",
      "Epoch 019/30 | Train: loss 0.4484 acc 0.9397 | Val: loss 0.6132 acc 0.8911 | Test: loss 0.5760 acc 0.8975 | LR: 5.00e-05\n",
      "Epoch 020/30 | Train: loss 0.4156 acc 0.9492 | Val: loss 0.5934 acc 0.8955 | Test: loss 0.5545 acc 0.8989 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8955\n",
      "Epoch 021/30 | Train: loss 0.3913 acc 0.9463 | Val: loss 0.5661 acc 0.9003 | Test: loss 0.5280 acc 0.8989 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9003\n",
      "Epoch 022/30 | Train: loss 0.3742 acc 0.9482 | Val: loss 0.5338 acc 0.9043 | Test: loss 0.4983 acc 0.9014 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9043\n",
      "Epoch 023/30 | Train: loss 0.3506 acc 0.9533 | Val: loss 0.5262 acc 0.9038 | Test: loss 0.4872 acc 0.9067 | LR: 5.00e-05\n",
      "Epoch 024/30 | Train: loss 0.3305 acc 0.9573 | Val: loss 0.5110 acc 0.9082 | Test: loss 0.4714 acc 0.9082 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9082\n",
      "Epoch 025/30 | Train: loss 0.3114 acc 0.9607 | Val: loss 0.4943 acc 0.9086 | Test: loss 0.4563 acc 0.9102 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9086\n",
      "Epoch 026/30 | Train: loss 0.2900 acc 0.9602 | Val: loss 0.4819 acc 0.9072 | Test: loss 0.4447 acc 0.9106 | LR: 5.00e-05\n",
      "Epoch 027/30 | Train: loss 0.2798 acc 0.9660 | Val: loss 0.4668 acc 0.9101 | Test: loss 0.4291 acc 0.9136 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9101\n",
      "Epoch 028/30 | Train: loss 0.2642 acc 0.9651 | Val: loss 0.4552 acc 0.9086 | Test: loss 0.4182 acc 0.9160 | LR: 5.00e-05\n",
      "Epoch 029/30 | Train: loss 0.2517 acc 0.9707 | Val: loss 0.4413 acc 0.9121 | Test: loss 0.4037 acc 0.9194 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9121\n",
      "Epoch 030/30 | Train: loss 0.2414 acc 0.9724 | Val: loss 0.4302 acc 0.9135 | Test: loss 0.3925 acc 0.9199 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9135\n",
      "\n",
      "============================================================\n",
      "FINAL EVALUATION\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "YOLOV5_CLS TRAINING SUMMARY\n",
      "============================================================\n",
      "Data split seed: 2\n",
      "Best epoch: 30\n",
      "Best validation accuracy: 0.9135\n",
      "Best validation loss: 0.4302\n",
      "Final test accuracy: 0.9199\n",
      "Final test loss: 0.3925\n",
      "Total epochs trained: 30\n",
      "\n",
      "Saved files:\n",
      "- Checkpoint: ./results/yolov5_cls_seed2\\best_yolov5_cls.pt\n",
      "- Accuracy curve: ./results/yolov5_cls_seed2\\accuracy_yolov5_cls.png\n",
      "- Loss curve: ./results/yolov5_cls_seed2\\loss_yolov5_cls.png\n",
      "- History: ./results/yolov5_cls_seed2\\history_yolov5_cls.json\n",
      "- Split indices: ./results/yolov5_cls_seed2\\split_indices_seed_2.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "h2_yolo_real, ckpt2_yolo_real = run_experiment(\n",
    "    model_type=\"yolov5_cls\",\n",
    "    data_root=r\"C:\\Users\\hp\\Downloads\\102flowers\",\n",
    "    split_seed=2,\n",
    "    out_dir=\"./results/yolov5_cls_seed2\",\n",
    "    epochs=30,\n",
    "    lr=5e-5,\n",
    "    freeze_backbone=True,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
