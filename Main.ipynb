{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c44d416d",
   "metadata": {},
   "source": [
    "VGG19 Transfer Learning on Oxford 102 Flowers Dataset\n",
    "\n",
    "Implements transfer learning with VGG19 and YOLOv5-CLS for flower classification.\n",
    "- Random split: 50/25/25 (train/val/test)\n",
    "- Run with different seeds: run_experiment(split_seed=1) and run_experiment(split_seed=2)\n",
    "- Saves training curves and model checkpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f00823dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Dataset, Subset\n",
    "from torchvision import datasets, models, transforms\n",
    "import csv\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import scipy.io as sio\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "268fc0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Flowers102Local(Dataset):\n",
    "    \"\"\"\n",
    "    Local Oxford 102 Flowers dataset:\n",
    "    root/\n",
    "      jpg/\n",
    "      imagelabels.mat\n",
    "      setid.mat\n",
    "    \"\"\"\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = Path(root)\n",
    "        self.img_dir = self.root / \"jpg\"\n",
    "        self.transform = transform\n",
    "\n",
    "        mat = sio.loadmat(self.root / \"imagelabels.mat\")\n",
    "        labels = mat[\"labels\"].squeeze().astype(int)  # 1..102\n",
    "        self.labels = (labels - 1).tolist()           # 0..101\n",
    "\n",
    "        self.image_paths = [\n",
    "            self.img_dir / f\"image_{i:05d}.jpg\"\n",
    "            for i in range(1, len(self.labels) + 1)\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "            path = self.image_paths[idx]\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            y = self.labels[idx]\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            return img, y, str(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6b8873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Dataset utilities\n",
    "# -----------------------------\n",
    "@dataclass\n",
    "class SplitIndices:\n",
    "    train: List[int]\n",
    "    val: List[int]\n",
    "    test: List[int]\n",
    "\n",
    "class TransformOverrideDataset(Dataset):\n",
    "    def __init__(self, base: Dataset, transform):\n",
    "        self.base = base\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.base[idx]\n",
    "        if len(sample) == 2:\n",
    "            x, y = sample\n",
    "            p = None\n",
    "        else:\n",
    "            x, y, p = sample\n",
    "\n",
    "        if self.transform is not None:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return (x, y) if p is None else (x, y, p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e65cddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_flowers102_all(root: str) -> Dataset:\n",
    "    return Flowers102Local(root=root, transform=None)\n",
    "\n",
    "\n",
    "def make_random_split_indices(n: int, split_seed: int) -> SplitIndices:\n",
    "    g = torch.Generator().manual_seed(split_seed)\n",
    "    perm = torch.randperm(n, generator=g).tolist()\n",
    "\n",
    "    n_train = int(0.50 * n)\n",
    "    n_val = int(0.25 * n)\n",
    "    n_test = n - n_train - n_val\n",
    "\n",
    "    train_idx = perm[:n_train]\n",
    "    val_idx = perm[n_train:n_train + n_val]\n",
    "    test_idx = perm[n_train + n_val:n_train + n_val + n_test]\n",
    "\n",
    "    return SplitIndices(train=train_idx, val=val_idx, test=test_idx)\n",
    "\n",
    "\n",
    "def save_split_indices(path: str, split: SplitIndices) -> None:\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"train\": split.train, \"val\": split.val, \"test\": split.test}, f)\n",
    "\n",
    "\n",
    "def load_split_indices(path: str) -> SplitIndices:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        obj = json.load(f)\n",
    "    return SplitIndices(train=obj[\"train\"], val=obj[\"val\"], test=obj[\"test\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06ce18a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transforms(img_size: int = 224):\n",
    "    imagenet_mean = [0.485, 0.456, 0.406]\n",
    "    imagenet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "    train_tf = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.02),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
    "    ])\n",
    "\n",
    "    eval_tf = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
    "    ])\n",
    "\n",
    "    return train_tf, eval_tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "681b4fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loaders(\n",
    "    root: str,\n",
    "    batch_size: int,\n",
    "    num_workers: int,\n",
    "    split_seed: int,\n",
    "    split_cache_path: str,\n",
    "    img_size: int = 224,\n",
    ") -> Tuple[DataLoader, DataLoader, DataLoader, SplitIndices]:\n",
    "    base_all = load_flowers102_all(root=root)\n",
    "    n = len(base_all)\n",
    "\n",
    "    if os.path.isfile(split_cache_path):\n",
    "        split = load_split_indices(split_cache_path)\n",
    "    else:\n",
    "        split = make_random_split_indices(n=n, split_seed=split_seed)\n",
    "        save_split_indices(split_cache_path, split)\n",
    "\n",
    "    train_tf, eval_tf = build_transforms(img_size=img_size)\n",
    "\n",
    "    train_ds = TransformOverrideDataset(Subset(base_all, split.train), transform=train_tf)\n",
    "    val_ds   = TransformOverrideDataset(Subset(base_all, split.val), transform=eval_tf)\n",
    "    test_ds  = TransformOverrideDataset(Subset(base_all, split.test), transform=eval_tf)\n",
    "\n",
    "    # In Windows notebooks, num_workers>0 can cause issues. Use 0 unless you know it's stable.\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=num_workers, pin_memory=True)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False,\n",
    "                              num_workers=num_workers, pin_memory=True)\n",
    "    test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False,\n",
    "                              num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    return train_loader, val_loader, test_loader, split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604ca076",
   "metadata": {},
   "source": [
    "Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f544c2a3",
   "metadata": {},
   "source": [
    "vgg19_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76ae9df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Model\n",
    "# -----------------------------\n",
    "def build_vgg19_classifier(num_classes: int = 102, freeze_features: bool = True) -> nn.Module:\n",
    "    model = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    if freeze_features:\n",
    "        for p in model.features.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    in_features = model.classifier[-1].in_features\n",
    "    model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c1a2d4",
   "metadata": {},
   "source": [
    "yolov5_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "667a8b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_yolov5_cls_classifier(\n",
    "    num_classes: int = 102,\n",
    "    freeze_backbone: bool = True,\n",
    "    weights: str = \"yolov5s-cls.pt\",\n",
    ") -> nn.Module:\n",
    "    \"\"\"\n",
    "    REAL YOLOv5 classifier using YOLOv5-CLS checkpoints (e.g., yolov5s-cls.pt).\n",
    "\n",
    "    - No fallback. If YOLOv5-CLS can't load, it raises an error.\n",
    "    - Replaces the final classifier layer to num_classes.\n",
    "    \"\"\"\n",
    "    print(f\"Loading REAL YOLOv5-CLS checkpoint: {weights}\")\n",
    "\n",
    "    # Load YOLOv5-CLS model from Ultralytics YOLOv5 repo via torch.hub\n",
    "    yolo = torch.hub.load(\n",
    "        \"ultralytics/yolov5\",\n",
    "        \"custom\",\n",
    "        path=weights,          # can be local path or model name if supported\n",
    "        autoshape=False,       # raw torch model for training\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    model = getattr(yolo, \"model\", None)\n",
    "    if model is None:\n",
    "        raise RuntimeError(\"Unexpected YOLOv5 hub return: missing `.model` attribute.\")\n",
    "\n",
    "    # For YOLOv5-CLS, last layer is typically a Classify module with `.linear`\n",
    "    head = model.model[-1]\n",
    "    if not hasattr(head, \"linear\"):\n",
    "        raise RuntimeError(\n",
    "            \"This does not look like a YOLOv5-CLS checkpoint (missing head.linear). \"\n",
    "            \"You probably loaded a detection checkpoint (e.g., yolov5s.pt). \"\n",
    "            \"Use yolov5s-cls.pt / yolov5m-cls.pt / yolov5l-cls.pt etc.\"\n",
    "        )\n",
    "\n",
    "    # Replace classifier\n",
    "    in_features = head.linear.in_features\n",
    "    head.linear = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    # Freeze backbone conditionally\n",
    "    if freeze_backbone:\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in head.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f579ee",
   "metadata": {},
   "source": [
    "Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4c413ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet50_classifier(num_classes: int = 102, freeze_backbone: bool = True) -> nn.Module:\n",
    "    \"\"\"Build ResNet50 model for transfer learning.\"\"\"\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    if freeze_backbone:\n",
    "        # Freeze all layers except the final classification layer\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    # Replace the final fully connected layer\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features, num_classes)\n",
    "    \n",
    "    # Always unfreeze the final layer\n",
    "    for param in model.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a9089ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for batch in loader:\n",
    "        if len(batch) == 2:\n",
    "            x, y = batch\n",
    "        else:\n",
    "            x, y, _paths = batch\n",
    "\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += x.size(0)\n",
    "\n",
    "    return total_loss / max(1, total), correct / max(1, total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67efd1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, device, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for batch in loader:\n",
    "        if len(batch) == 2:\n",
    "            x, y = batch\n",
    "        else:\n",
    "            x, y, _paths = batch  # ignore paths during training\n",
    "\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y = y.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += x.size(0)\n",
    "\n",
    "    return total_loss / max(1, total), correct / max(1, total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "568d4d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_curves(out_dir: str, history: Dict[str, List[float]]) -> None:\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(history[\"train_acc\"], label=\"train\")\n",
    "    plt.plot(history[\"val_acc\"], label=\"val\")\n",
    "    plt.plot(history[\"test_acc\"], label=\"test\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, \"accuracy_vgg19.png\"), dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(history[\"train_loss\"], label=\"train\")\n",
    "    plt.plot(history[\"val_loss\"], label=\"val\")\n",
    "    plt.plot(history[\"test_loss\"], label=\"test\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"cross_entropy\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, \"loss_vgg19.png\"), dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "    with open(os.path.join(out_dir, \"history_vgg19.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(history, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8154c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_checkpoint(path: str, model: nn.Module, optimizer: optim.Optimizer, epoch: int, best_val_acc: float) -> None:\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    torch.save(\n",
    "        {\"epoch\": epoch, \"model_state\": model.state_dict(),\n",
    "         \"optimizer_state\": optimizer.state_dict(), \"best_val_acc\": best_val_acc},\n",
    "        path,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd1a9faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def predict_proba(model: nn.Module, images: torch.Tensor, device: torch.device) -> torch.Tensor:\n",
    "    model.eval()\n",
    "    images = images.to(device)\n",
    "    logits = model(images)\n",
    "    return torch.softmax(logits, dim=1).cpu()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70b8deb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def export_probs_csv(model, loader, device, out_csv: str):\n",
    "    model.eval()\n",
    "    header = [\"path\", \"true_label\"] + [f\"p_{i:03d}\" for i in range(102)]\n",
    "\n",
    "    with open(out_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow(header)\n",
    "\n",
    "        for batch in loader:\n",
    "            if len(batch) == 2:\n",
    "                images, labels = batch\n",
    "                paths = [\"\" for _ in range(images.size(0))]\n",
    "            else:\n",
    "                images, labels, paths = batch\n",
    "\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            probs = torch.softmax(model(images), dim=1).cpu()  # (B,102)\n",
    "\n",
    "            for i in range(probs.size(0)):\n",
    "                row = [paths[i], int(labels[i])] + probs[i].tolist()\n",
    "                w.writerow(row)\n",
    "\n",
    "    print(\"Saved:\", out_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bff9727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    model_type: str = \"vgg19\",  # \"vgg19\", \"resnet50\", or \"yolov5\"\n",
    "    data_root: str = \"./data\",\n",
    "    out_dir: str = \"./results/vgg19_seed1\",\n",
    "    epochs: int = 35,\n",
    "    batch_size: int = 32,\n",
    "    lr: float = 1e-4,\n",
    "    weight_decay: float = 0.0,\n",
    "    num_workers: int = 0,\n",
    "    img_size: int = 224,\n",
    "    split_seed: int = 1,\n",
    "    freeze_backbone: bool = True,\n",
    "    early_stop_patience: int = 7,\n",
    "    device: str = \"cuda\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Main training function for flower classification.\n",
    "    \n",
    "    Args:\n",
    "        model_type: \"vgg19\", \"resnet50\", or \"yolov5\"\n",
    "        data_root: Path to dataset root directory\n",
    "        out_dir: Output directory for results\n",
    "        epochs: Maximum number of training epochs\n",
    "        batch_size: Batch size for training\n",
    "        lr: Learning rate (will be adjusted based on model_type)\n",
    "        weight_decay: Weight decay for optimizer\n",
    "        num_workers: Number of data loader workers\n",
    "        img_size: Input image size\n",
    "        split_seed: Random seed for data split\n",
    "        freeze_backbone: Whether to freeze pre-trained backbone\n",
    "        early_stop_patience: Early stopping patience\n",
    "        device: \"cuda\" or \"cpu\"\n",
    "    \n",
    "    Returns:\n",
    "        history: Dictionary with training history\n",
    "        ckpt_path: Path to best model checkpoint\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set device\n",
    "    if device == \"cuda\" and not torch.cuda.is_available():\n",
    "        print(\"CUDA requested but not available. Falling back to CPU.\")\n",
    "        device = \"cpu\"\n",
    "    device_t = torch.device(device)\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    \n",
    "    # Set random seeds for reproducibility\n",
    "    set_seed(split_seed)\n",
    "    \n",
    "    # Split cache path\n",
    "    split_cache_path = os.path.join(out_dir, f\"split_indices_seed_{split_seed}.json\")\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader, val_loader, test_loader, _split = make_loaders(\n",
    "        root=data_root,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        split_seed=split_seed,\n",
    "        split_cache_path=split_cache_path,\n",
    "        img_size=img_size,\n",
    "    )\n",
    "    \n",
    "    # Build model based on type\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_type.upper()} - Split Seed: {split_seed}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Initialize variables\n",
    "    model = None\n",
    "    unfrozen_params = None\n",
    "    model_name = model_type.lower()  # Define model_name here\n",
    "    \n",
    "    if model_name == \"vgg19\":\n",
    "        # VGG19 model\n",
    "        model = build_vgg19_classifier(num_classes=102, freeze_features=freeze_backbone)\n",
    "        if lr == 1e-4:  # Default value\n",
    "            lr = 1e-4  # Good starting point for VGG19\n",
    "        # Get unfrozen parameters (only the last classifier layer if frozen)\n",
    "        if freeze_backbone:\n",
    "            unfrozen_params = [p for p in model.classifier[-1].parameters()]\n",
    "        else:\n",
    "            unfrozen_params = model.parameters()\n",
    "            \n",
    "    elif model_name == \"resnet50\":\n",
    "        # ResNet50 model\n",
    "        model = build_resnet50_classifier(num_classes=102, freeze_backbone=freeze_backbone)\n",
    "        if lr == 1e-4:  # Default value\n",
    "            lr = 1e-4  # Good starting point for ResNet50\n",
    "        # Get unfrozen parameters\n",
    "        if freeze_backbone:\n",
    "            unfrozen_params = [p for p in model.fc.parameters()]\n",
    "        else:\n",
    "            unfrozen_params = model.parameters()\n",
    "            \n",
    "    elif model_name in [\"yolov5_cls\", \"yolov5-cls\", \"yolov5\"]:\n",
    "        # YOLOv5-based model\n",
    "        model = build_yolov5_cls_classifier(num_classes=102, freeze_backbone=freeze_backbone)\n",
    "        model_name = \"yolov5\"  # Standardize name\n",
    "        if lr == 1e-4:  # Default value\n",
    "            lr = 5e-5  # Lower learning rate for YOLOv5\n",
    "        # Get unfrozen parameters\n",
    "        if freeze_backbone:\n",
    "            head = model.model[-1]  # Classify module\n",
    "            unfrozen_params = list(head.parameters())\n",
    "        else:\n",
    "            unfrozen_params = model.parameters()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}. Choose from 'vgg19', 'resnet50', or 'yolov5'.\")\n",
    "    \n",
    "    # Safety check\n",
    "    if model is None:\n",
    "        raise RuntimeError(\"Model was not built properly.\")\n",
    "    if unfrozen_params is None:\n",
    "        raise RuntimeError(\"Unfrozen parameters were not set properly.\")\n",
    "    \n",
    "    # Move model to device\n",
    "    model = model.to(device_t)\n",
    "    \n",
    "    # Print model summary\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in unfrozen_params)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"Frozen parameters: {total_params - trainable_params:,}\")\n",
    "    print(f\"Learning rate: {lr}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    print(f\"Epochs: {epochs}\")\n",
    "    \n",
    "    # Define optimizer - only optimize trainable parameters\n",
    "    optimizer = optim.Adam(unfrozen_params, lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=3)\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Initialize history tracking\n",
    "    history = {\n",
    "        \"train_loss\": [], \"val_loss\": [], \"test_loss\": [],\n",
    "        \"train_acc\": [], \"val_acc\": [], \"test_acc\": [],\n",
    "        \"learning_rate\": []\n",
    "    }\n",
    "    \n",
    "    # Early stopping variables\n",
    "    best_val_acc = -1.0\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_epoch = 0\n",
    "    \n",
    "    # Checkpoint path\n",
    "    ckpt_path = os.path.join(out_dir, f\"best_{model_name}.pt\")\n",
    "    \n",
    "    # Training loop\n",
    "    print(f\"\\nStarting training for {epochs} epochs...\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Training phase\n",
    "        tr_loss, tr_acc = train_one_epoch(model, train_loader, device_t, criterion, optimizer)\n",
    "        \n",
    "        # Validation phase\n",
    "        va_loss, va_acc = evaluate(model, val_loader, device_t, criterion)\n",
    "        \n",
    "        # Test phase (for monitoring, not for early stopping)\n",
    "        te_loss, te_acc = evaluate(model, test_loader, device_t, criterion)\n",
    "        \n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step(va_loss)\n",
    "        \n",
    "        # Record history\n",
    "        history[\"train_loss\"].append(tr_loss)\n",
    "        history[\"val_loss\"].append(va_loss)\n",
    "        history[\"test_loss\"].append(te_loss)\n",
    "        history[\"train_acc\"].append(tr_acc)\n",
    "        history[\"val_acc\"].append(va_acc)\n",
    "        history[\"test_acc\"].append(te_acc)\n",
    "        history[\"learning_rate\"].append(optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        # Print progress\n",
    "        print(\n",
    "            f\"Epoch {epoch:03d}/{epochs} | \"\n",
    "            f\"Train: loss {tr_loss:.4f} acc {tr_acc:.4f} | \"\n",
    "            f\"Val: loss {va_loss:.4f} acc {va_acc:.4f} | \"\n",
    "            f\"Test: loss {te_loss:.4f} acc {te_acc:.4f} | \"\n",
    "            f\"LR: {history['learning_rate'][-1]:.2e}\"\n",
    "        )\n",
    "        \n",
    "        # Check for improvement in validation accuracy\n",
    "        if va_acc > best_val_acc:\n",
    "            best_val_acc = va_acc\n",
    "            best_val_loss = va_loss\n",
    "            best_epoch = epoch\n",
    "            epochs_no_improve = 0\n",
    "            \n",
    "            # Save best model checkpoint\n",
    "            save_checkpoint(ckpt_path, model, optimizer, epoch, best_val_acc)\n",
    "            print(f\"✓ New best model saved! Val Acc: {best_val_acc:.4f}\")\n",
    "            \n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= early_stop_patience:\n",
    "                print(f\"\\nEarly stopping triggered at epoch {epoch}. \"\n",
    "                      f\"No improvement for {early_stop_patience} epochs.\")\n",
    "                break\n",
    "        \n",
    "        # Additional: save checkpoint every 5 epochs\n",
    "        if epoch % 5 == 0 and epoch != best_epoch:\n",
    "            intermediate_ckpt = os.path.join(out_dir, f\"{model_name}_epoch_{epoch}.pt\")\n",
    "            save_checkpoint(intermediate_ckpt, model, optimizer, epoch, va_acc)\n",
    "    \n",
    "    # Final evaluation on test set with best model\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL EVALUATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load best model\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device_t)\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    final_test_loss, final_test_acc = evaluate(model, test_loader, device_t, criterion)\n",
    "    \n",
    "    # Save training curves\n",
    "    save_curves(out_dir, history, model_name=model_name)\n",
    "    \n",
    "    # Export probabilities\n",
    "    export_probs_csv(\n",
    "        model=model,\n",
    "        loader=test_loader,\n",
    "        device=device_t,\n",
    "        out_csv=os.path.join(out_dir, f\"test_probs_{model_name}_seed{split_seed}.csv\"),\n",
    "    )\n",
    "\n",
    "    # Save full history\n",
    "    history_path = os.path.join(out_dir, f\"history_{model_name}.json\")\n",
    "    with open(history_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({k: [float(v) for v in vals] for k, vals in history.items()}, f, indent=2)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{model_name.upper()} TRAINING SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Data split seed: {split_seed}\")\n",
    "    print(f\"Best epoch: {best_epoch}\")\n",
    "    print(f\"Best validation accuracy: {best_val_acc:.4f}\")\n",
    "    print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "    print(f\"Final test accuracy: {final_test_acc:.4f}\")\n",
    "    print(f\"Final test loss: {final_test_loss:.4f}\")\n",
    "    print(f\"Total epochs trained: {len(history['train_acc'])}\")\n",
    "    \n",
    "    print(f\"\\nSaved files:\")\n",
    "    print(f\"- Checkpoint: {ckpt_path}\")\n",
    "    print(f\"- Accuracy curve: {os.path.join(out_dir, f'training_curves_{model_name}.png')}\")\n",
    "    print(f\"- Loss curve: {os.path.join(out_dir, f'training_curves_{model_name}.png')}\")\n",
    "    print(f\"- History: {history_path}\")\n",
    "    print(f\"- Split indices: {split_cache_path}\")\n",
    "    print(f\"- Test probabilities: {os.path.join(out_dir, f'test_probs_{model_name}_seed{split_seed}.csv')}\")\n",
    "    \n",
    "    # Add final test metrics to history\n",
    "    history[\"final_test_acc\"] = final_test_acc\n",
    "    history[\"final_test_loss\"] = final_test_loss\n",
    "    history[\"best_val_acc\"] = best_val_acc\n",
    "    history[\"best_epoch\"] = best_epoch\n",
    "    history[\"model_type\"] = model_name\n",
    "    history[\"split_seed\"] = split_seed\n",
    "\n",
    "    return history, ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6481fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Modified save_curves to support both models\n",
    "def save_curves(out_dir: str, history: Dict[str, List[float]], model_name: str = \"model\") -> None:\n",
    "    \"\"\"\n",
    "    Save accuracy and loss curves for the model.\n",
    "    \"\"\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history[\"train_acc\"], label=\"Train\", linewidth=2)\n",
    "    plt.plot(history[\"val_acc\"], label=\"Validation\", linewidth=2)\n",
    "    plt.plot(history[\"test_acc\"], label=\"Test\", linewidth=2)\n",
    "    plt.axhline(y=0.70, color='gray', linestyle='--', alpha=0.7, label='70% Requirement')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(f\"{model_name.upper()} - Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history[\"train_loss\"], label=\"Train\", linewidth=2)\n",
    "    plt.plot(history[\"val_loss\"], label=\"Validation\", linewidth=2)\n",
    "    plt.plot(history[\"test_loss\"], label=\"Test\", linewidth=2)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Cross-Entropy Loss\")\n",
    "    plt.title(f\"{model_name.upper()} - Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(out_dir, f\"training_curves_{model_name}.png\"), dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Learning rate plot\n",
    "    if \"learning_rate\" in history:\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.plot(history[\"learning_rate\"], linewidth=2)\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Learning Rate\")\n",
    "        plt.title(f\"{model_name.upper()} - Learning Rate Schedule\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(out_dir, f\"learning_rate_{model_name}.png\"), dpi=150, bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a76888dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # Determinism (can reduce speed; )\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0bb88ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training VGG19 - Split Seed: 1\n",
      "============================================================\n",
      "Model: vgg19\n",
      "Total parameters: 139,988,134\n",
      "Trainable parameters: 417,894\n",
      "Frozen parameters: 139,570,240\n",
      "Learning rate: 0.0001\n",
      "\n",
      "Starting training for 35 epochs...\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 001/35 | Train: loss 4.0681 acc 0.1136 | Val: loss 3.4840 acc 0.3214 | Test: loss 3.5004 acc 0.3071 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.3214\n",
      "Epoch 002/35 | Train: loss 3.1044 acc 0.3356 | Val: loss 2.8805 acc 0.4455 | Test: loss 2.9096 acc 0.4224 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.4455\n",
      "Epoch 003/35 | Train: loss 2.5820 acc 0.4673 | Val: loss 2.4969 acc 0.5266 | Test: loss 2.5175 acc 0.5122 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.5266\n",
      "Epoch 004/35 | Train: loss 2.2639 acc 0.5305 | Val: loss 2.2330 acc 0.5843 | Test: loss 2.2610 acc 0.5771 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.5843\n",
      "Epoch 005/35 | Train: loss 2.0190 acc 0.5850 | Val: loss 2.0416 acc 0.6170 | Test: loss 2.0683 acc 0.6021 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.6170\n",
      "Epoch 006/35 | Train: loss 1.8322 acc 0.6226 | Val: loss 1.8944 acc 0.6307 | Test: loss 1.9278 acc 0.6182 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.6307\n",
      "Epoch 007/35 | Train: loss 1.6961 acc 0.6431 | Val: loss 1.7774 acc 0.6473 | Test: loss 1.8098 acc 0.6411 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.6473\n",
      "Epoch 008/35 | Train: loss 1.5826 acc 0.6615 | Val: loss 1.6828 acc 0.6615 | Test: loss 1.7181 acc 0.6543 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.6615\n",
      "Epoch 009/35 | Train: loss 1.5140 acc 0.6732 | Val: loss 1.6068 acc 0.6663 | Test: loss 1.6399 acc 0.6650 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.6663\n",
      "Epoch 010/35 | Train: loss 1.4248 acc 0.6900 | Val: loss 1.5326 acc 0.6776 | Test: loss 1.5686 acc 0.6743 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.6776\n",
      "Epoch 011/35 | Train: loss 1.3620 acc 0.7035 | Val: loss 1.4727 acc 0.6883 | Test: loss 1.5089 acc 0.6934 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.6883\n",
      "Epoch 012/35 | Train: loss 1.2956 acc 0.7196 | Val: loss 1.4258 acc 0.6908 | Test: loss 1.4624 acc 0.6948 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.6908\n",
      "Epoch 013/35 | Train: loss 1.2715 acc 0.7181 | Val: loss 1.3860 acc 0.6922 | Test: loss 1.4230 acc 0.7021 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.6922\n",
      "Epoch 014/35 | Train: loss 1.2157 acc 0.7294 | Val: loss 1.3421 acc 0.7030 | Test: loss 1.3790 acc 0.7031 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7030\n",
      "Epoch 015/35 | Train: loss 1.1747 acc 0.7237 | Val: loss 1.3077 acc 0.7098 | Test: loss 1.3421 acc 0.7026 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7098\n",
      "Epoch 016/35 | Train: loss 1.1425 acc 0.7352 | Val: loss 1.2703 acc 0.7113 | Test: loss 1.3056 acc 0.7173 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7113\n",
      "Epoch 017/35 | Train: loss 1.1147 acc 0.7384 | Val: loss 1.2422 acc 0.7147 | Test: loss 1.2792 acc 0.7183 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7147\n",
      "Epoch 018/35 | Train: loss 1.0867 acc 0.7479 | Val: loss 1.2123 acc 0.7196 | Test: loss 1.2509 acc 0.7236 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7196\n",
      "Epoch 019/35 | Train: loss 1.0538 acc 0.7489 | Val: loss 1.1962 acc 0.7255 | Test: loss 1.2328 acc 0.7227 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7255\n",
      "Epoch 020/35 | Train: loss 1.0210 acc 0.7572 | Val: loss 1.1657 acc 0.7323 | Test: loss 1.1994 acc 0.7319 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7323\n",
      "Epoch 021/35 | Train: loss 0.9877 acc 0.7653 | Val: loss 1.1474 acc 0.7274 | Test: loss 1.1841 acc 0.7339 | LR: 1.00e-04\n",
      "Epoch 022/35 | Train: loss 0.9695 acc 0.7775 | Val: loss 1.1258 acc 0.7294 | Test: loss 1.1656 acc 0.7368 | LR: 1.00e-04\n",
      "Epoch 023/35 | Train: loss 0.9654 acc 0.7741 | Val: loss 1.1103 acc 0.7333 | Test: loss 1.1535 acc 0.7412 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7333\n",
      "Epoch 024/35 | Train: loss 0.9262 acc 0.7765 | Val: loss 1.0999 acc 0.7342 | Test: loss 1.1382 acc 0.7329 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7342\n",
      "Epoch 025/35 | Train: loss 0.9269 acc 0.7777 | Val: loss 1.0785 acc 0.7396 | Test: loss 1.1176 acc 0.7422 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7396\n",
      "Epoch 026/35 | Train: loss 0.8983 acc 0.7794 | Val: loss 1.0641 acc 0.7460 | Test: loss 1.1009 acc 0.7437 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7460\n",
      "Epoch 027/35 | Train: loss 0.9023 acc 0.7804 | Val: loss 1.0496 acc 0.7518 | Test: loss 1.0870 acc 0.7451 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7518\n",
      "Epoch 028/35 | Train: loss 0.8658 acc 0.7890 | Val: loss 1.0374 acc 0.7499 | Test: loss 1.0747 acc 0.7456 | LR: 1.00e-04\n",
      "Epoch 029/35 | Train: loss 0.8595 acc 0.7943 | Val: loss 1.0244 acc 0.7533 | Test: loss 1.0605 acc 0.7495 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7533\n",
      "Epoch 030/35 | Train: loss 0.8611 acc 0.7872 | Val: loss 1.0148 acc 0.7518 | Test: loss 1.0500 acc 0.7505 | LR: 1.00e-04\n",
      "Epoch 031/35 | Train: loss 0.8295 acc 0.7968 | Val: loss 1.0019 acc 0.7557 | Test: loss 1.0405 acc 0.7549 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7557\n",
      "Epoch 032/35 | Train: loss 0.8280 acc 0.7938 | Val: loss 0.9913 acc 0.7553 | Test: loss 1.0287 acc 0.7529 | LR: 1.00e-04\n",
      "Epoch 033/35 | Train: loss 0.8232 acc 0.7995 | Val: loss 0.9717 acc 0.7562 | Test: loss 1.0144 acc 0.7520 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7562\n",
      "Epoch 034/35 | Train: loss 0.8075 acc 0.8002 | Val: loss 0.9673 acc 0.7626 | Test: loss 1.0066 acc 0.7642 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7626\n",
      "Epoch 035/35 | Train: loss 0.7820 acc 0.8087 | Val: loss 0.9614 acc 0.7592 | Test: loss 1.0036 acc 0.7573 | LR: 1.00e-04\n",
      "\n",
      "============================================================\n",
      "FINAL EVALUATION\n",
      "============================================================\n",
      "Training curves saved in ./results/vgg19_seed1\n",
      "Saved: ./results/vgg19_seed1\\probs_vgg19.csv\n",
      "Saved: ./results/vgg19_seed1\\test_probs_vgg19_seed1.csv\n",
      "\n",
      "============================================================\n",
      "VGG19 TRAINING SUMMARY\n",
      "============================================================\n",
      "Data split seed: 1\n",
      "Best epoch: 34\n",
      "Best validation accuracy: 0.7626\n",
      "Best validation loss: 0.9673\n",
      "Final test accuracy: 0.7642\n",
      "Final test loss: 1.0066\n",
      "Total epochs trained: 35\n",
      "\n",
      "Saved files:\n",
      "- Checkpoint: ./results/vgg19_seed1\\best_vgg19.pt\n",
      "- Accuracy curve: ./results/vgg19_seed1\\accuracy_vgg19.png\n",
      "- Loss curve: ./results/vgg19_seed1\\loss_vgg19.png\n",
      "- History: ./results/vgg19_seed1\\history_vgg19.json\n",
      "- Split indices: ./results/vgg19_seed1\\split_indices_seed_1.json\n"
     ]
    }
   ],
   "source": [
    "h1, ckpt1 = run_experiment(\n",
    "    data_root=r\"C:\\Users\\hp\\Downloads\\102flowers\",\n",
    "    split_seed=1,\n",
    "    out_dir=\"./results/vgg19_seed1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9634ef89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training VGG19 - Split Seed: 2\n",
      "============================================================\n",
      "Model: vgg19\n",
      "Total parameters: 139,988,134\n",
      "Trainable parameters: 417,894\n",
      "Frozen parameters: 139,570,240\n",
      "Learning rate: 0.0001\n",
      "\n",
      "Starting training for 35 epochs...\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 001/35 | Train: loss 4.0723 acc 0.1197 | Val: loss 3.4878 acc 0.2995 | Test: loss 3.4551 acc 0.3154 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.2995\n",
      "Epoch 002/35 | Train: loss 3.1211 acc 0.3339 | Val: loss 2.8876 acc 0.4372 | Test: loss 2.8433 acc 0.4619 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.4372\n",
      "Epoch 003/35 | Train: loss 2.6091 acc 0.4511 | Val: loss 2.5152 acc 0.5242 | Test: loss 2.4717 acc 0.5605 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.5242\n",
      "Epoch 004/35 | Train: loss 2.2734 acc 0.5286 | Val: loss 2.2528 acc 0.5760 | Test: loss 2.2079 acc 0.6094 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.5760\n",
      "Epoch 005/35 | Train: loss 2.0338 acc 0.5794 | Val: loss 2.0709 acc 0.5984 | Test: loss 2.0158 acc 0.6372 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.5984\n",
      "Epoch 006/35 | Train: loss 1.8665 acc 0.6021 | Val: loss 1.9287 acc 0.6146 | Test: loss 1.8681 acc 0.6523 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.6146\n",
      "Epoch 007/35 | Train: loss 1.7237 acc 0.6351 | Val: loss 1.8123 acc 0.6326 | Test: loss 1.7462 acc 0.6699 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.6326\n",
      "Epoch 008/35 | Train: loss 1.6167 acc 0.6466 | Val: loss 1.7149 acc 0.6483 | Test: loss 1.6526 acc 0.6904 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.6483\n",
      "Epoch 009/35 | Train: loss 1.5338 acc 0.6663 | Val: loss 1.6439 acc 0.6571 | Test: loss 1.5809 acc 0.6938 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.6571\n",
      "Epoch 010/35 | Train: loss 1.4430 acc 0.6815 | Val: loss 1.5709 acc 0.6683 | Test: loss 1.5062 acc 0.6997 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.6683\n",
      "Epoch 011/35 | Train: loss 1.3846 acc 0.6917 | Val: loss 1.5232 acc 0.6746 | Test: loss 1.4525 acc 0.7046 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.6746\n",
      "Epoch 012/35 | Train: loss 1.3250 acc 0.7000 | Val: loss 1.4674 acc 0.6839 | Test: loss 1.3935 acc 0.7114 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.6839\n",
      "Epoch 013/35 | Train: loss 1.2823 acc 0.7076 | Val: loss 1.4175 acc 0.6893 | Test: loss 1.3492 acc 0.7178 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.6893\n",
      "Epoch 014/35 | Train: loss 1.2368 acc 0.7171 | Val: loss 1.3888 acc 0.6903 | Test: loss 1.3196 acc 0.7178 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.6903\n",
      "Epoch 015/35 | Train: loss 1.1897 acc 0.7289 | Val: loss 1.3569 acc 0.6971 | Test: loss 1.2845 acc 0.7212 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.6971\n",
      "Epoch 016/35 | Train: loss 1.1548 acc 0.7404 | Val: loss 1.3240 acc 0.7088 | Test: loss 1.2511 acc 0.7275 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7088\n",
      "Epoch 017/35 | Train: loss 1.1081 acc 0.7531 | Val: loss 1.2931 acc 0.7074 | Test: loss 1.2202 acc 0.7319 | LR: 1.00e-04\n",
      "Epoch 018/35 | Train: loss 1.1026 acc 0.7411 | Val: loss 1.2641 acc 0.7098 | Test: loss 1.1958 acc 0.7402 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7098\n",
      "Epoch 019/35 | Train: loss 1.0757 acc 0.7501 | Val: loss 1.2397 acc 0.7196 | Test: loss 1.1686 acc 0.7427 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7196\n",
      "Epoch 020/35 | Train: loss 1.0634 acc 0.7438 | Val: loss 1.2165 acc 0.7230 | Test: loss 1.1462 acc 0.7402 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7230\n",
      "Epoch 021/35 | Train: loss 1.0335 acc 0.7469 | Val: loss 1.1971 acc 0.7240 | Test: loss 1.1243 acc 0.7490 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7240\n",
      "Epoch 022/35 | Train: loss 1.0001 acc 0.7618 | Val: loss 1.1760 acc 0.7289 | Test: loss 1.1024 acc 0.7554 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7289\n",
      "Epoch 023/35 | Train: loss 0.9894 acc 0.7670 | Val: loss 1.1540 acc 0.7352 | Test: loss 1.0792 acc 0.7544 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7352\n",
      "Epoch 024/35 | Train: loss 0.9522 acc 0.7682 | Val: loss 1.1431 acc 0.7367 | Test: loss 1.0666 acc 0.7573 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7367\n",
      "Epoch 025/35 | Train: loss 0.9461 acc 0.7753 | Val: loss 1.1274 acc 0.7416 | Test: loss 1.0478 acc 0.7563 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7416\n",
      "Epoch 026/35 | Train: loss 0.9237 acc 0.7802 | Val: loss 1.1105 acc 0.7386 | Test: loss 1.0347 acc 0.7603 | LR: 1.00e-04\n",
      "Epoch 027/35 | Train: loss 0.8952 acc 0.7838 | Val: loss 1.1013 acc 0.7386 | Test: loss 1.0271 acc 0.7607 | LR: 1.00e-04\n",
      "Epoch 028/35 | Train: loss 0.9012 acc 0.7826 | Val: loss 1.0899 acc 0.7411 | Test: loss 1.0122 acc 0.7563 | LR: 1.00e-04\n",
      "Epoch 029/35 | Train: loss 0.8860 acc 0.7836 | Val: loss 1.0746 acc 0.7469 | Test: loss 0.9954 acc 0.7637 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7469\n",
      "Epoch 030/35 | Train: loss 0.8630 acc 0.7853 | Val: loss 1.0664 acc 0.7504 | Test: loss 0.9915 acc 0.7651 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7504\n",
      "Epoch 031/35 | Train: loss 0.8665 acc 0.7882 | Val: loss 1.0514 acc 0.7523 | Test: loss 0.9770 acc 0.7671 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7523\n",
      "Epoch 032/35 | Train: loss 0.8508 acc 0.7997 | Val: loss 1.0430 acc 0.7513 | Test: loss 0.9673 acc 0.7632 | LR: 1.00e-04\n",
      "Epoch 033/35 | Train: loss 0.8354 acc 0.7860 | Val: loss 1.0298 acc 0.7538 | Test: loss 0.9579 acc 0.7705 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7538\n",
      "Epoch 034/35 | Train: loss 0.8120 acc 0.7943 | Val: loss 1.0229 acc 0.7592 | Test: loss 0.9475 acc 0.7715 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7592\n",
      "Epoch 035/35 | Train: loss 0.7855 acc 0.8090 | Val: loss 1.0115 acc 0.7596 | Test: loss 0.9365 acc 0.7734 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7596\n",
      "\n",
      "============================================================\n",
      "FINAL EVALUATION\n",
      "============================================================\n",
      "Training curves saved in ./results/vgg19_seed2\n",
      "Saved: ./results/vgg19_seed2\\probs_vgg19.csv\n",
      "Saved: ./results/vgg19_seed2\\test_probs_vgg19_seed2.csv\n",
      "\n",
      "============================================================\n",
      "VGG19 TRAINING SUMMARY\n",
      "============================================================\n",
      "Data split seed: 2\n",
      "Best epoch: 35\n",
      "Best validation accuracy: 0.7596\n",
      "Best validation loss: 1.0115\n",
      "Final test accuracy: 0.7734\n",
      "Final test loss: 0.9365\n",
      "Total epochs trained: 35\n",
      "\n",
      "Saved files:\n",
      "- Checkpoint: ./results/vgg19_seed2\\best_vgg19.pt\n",
      "- Accuracy curve: ./results/vgg19_seed2\\accuracy_vgg19.png\n",
      "- Loss curve: ./results/vgg19_seed2\\loss_vgg19.png\n",
      "- History: ./results/vgg19_seed2\\history_vgg19.json\n",
      "- Split indices: ./results/vgg19_seed2\\split_indices_seed_2.json\n"
     ]
    }
   ],
   "source": [
    "h2, ckpt2 = run_experiment(\n",
    "    data_root=r\"C:\\Users\\hp\\Downloads\\102flowers\",\n",
    "    split_seed=2,\n",
    "    out_dir=\"./results/vgg19_seed2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2810fe",
   "metadata": {},
   "source": [
    "Yolov5 fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "061175e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== REAL YOLOv5-CLS Experiments ===\n",
      "\n",
      "============================================================\n",
      "Training YOLOV5_CLS - Split Seed: 1\n",
      "============================================================\n",
      "Loading REAL YOLOv5-CLS checkpoint: yolov5s-cls.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2026-1-14 Python-3.13.5 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: yolov5\n",
      "Total parameters: 4,303,142\n",
      "Trainable parameters: 788,582\n",
      "Frozen parameters: 3,514,560\n",
      "Learning rate: 5e-05\n",
      "\n",
      "Starting training for 30 epochs...\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 001/30 | Train: loss 4.2718 acc 0.1063 | Val: loss 3.8966 acc 0.2428 | Test: loss 3.9262 acc 0.2139 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.2428\n",
      "Epoch 002/30 | Train: loss 3.5577 acc 0.3136 | Val: loss 3.2747 acc 0.3884 | Test: loss 3.3098 acc 0.3711 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.3884\n",
      "Epoch 003/30 | Train: loss 2.9450 acc 0.4934 | Val: loss 2.7561 acc 0.5032 | Test: loss 2.7872 acc 0.5015 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.5032\n",
      "Epoch 004/30 | Train: loss 2.4163 acc 0.6087 | Val: loss 2.3015 acc 0.6185 | Test: loss 2.3276 acc 0.6265 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.6185\n",
      "Epoch 005/30 | Train: loss 1.9961 acc 0.7171 | Val: loss 1.9385 acc 0.6790 | Test: loss 1.9541 acc 0.6909 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.6790\n",
      "Epoch 006/30 | Train: loss 1.6719 acc 0.7587 | Val: loss 1.6967 acc 0.7279 | Test: loss 1.7053 acc 0.7383 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7279\n",
      "Epoch 007/30 | Train: loss 1.4243 acc 0.8085 | Val: loss 1.4675 acc 0.7645 | Test: loss 1.4765 acc 0.7744 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7645\n",
      "Epoch 008/30 | Train: loss 1.2315 acc 0.8339 | Val: loss 1.3176 acc 0.7846 | Test: loss 1.3201 acc 0.7979 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7846\n",
      "Epoch 009/30 | Train: loss 1.0767 acc 0.8596 | Val: loss 1.1645 acc 0.8105 | Test: loss 1.1617 acc 0.8169 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8105\n",
      "Epoch 010/30 | Train: loss 0.9539 acc 0.8713 | Val: loss 1.0575 acc 0.8300 | Test: loss 1.0546 acc 0.8325 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8300\n",
      "Epoch 011/30 | Train: loss 0.8462 acc 0.8937 | Val: loss 0.9725 acc 0.8456 | Test: loss 0.9676 acc 0.8408 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8456\n",
      "Epoch 012/30 | Train: loss 0.7709 acc 0.9013 | Val: loss 0.8952 acc 0.8564 | Test: loss 0.8886 acc 0.8530 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8564\n",
      "Epoch 013/30 | Train: loss 0.6986 acc 0.9064 | Val: loss 0.8335 acc 0.8661 | Test: loss 0.8283 acc 0.8652 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8661\n",
      "Epoch 014/30 | Train: loss 0.6446 acc 0.9155 | Val: loss 0.7658 acc 0.8764 | Test: loss 0.7561 acc 0.8765 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8764\n",
      "Epoch 015/30 | Train: loss 0.6000 acc 0.9201 | Val: loss 0.7384 acc 0.8784 | Test: loss 0.7305 acc 0.8770 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8784\n",
      "Epoch 016/30 | Train: loss 0.5568 acc 0.9284 | Val: loss 0.6968 acc 0.8842 | Test: loss 0.6890 acc 0.8818 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8842\n",
      "Epoch 017/30 | Train: loss 0.5106 acc 0.9350 | Val: loss 0.6608 acc 0.8896 | Test: loss 0.6531 acc 0.8862 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8896\n",
      "Epoch 018/30 | Train: loss 0.4736 acc 0.9406 | Val: loss 0.6212 acc 0.8920 | Test: loss 0.6105 acc 0.8911 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8920\n",
      "Epoch 019/30 | Train: loss 0.4407 acc 0.9450 | Val: loss 0.5939 acc 0.8959 | Test: loss 0.5854 acc 0.8970 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8959\n",
      "Epoch 020/30 | Train: loss 0.4138 acc 0.9465 | Val: loss 0.5648 acc 0.8994 | Test: loss 0.5571 acc 0.8960 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8994\n",
      "Epoch 021/30 | Train: loss 0.3920 acc 0.9487 | Val: loss 0.5533 acc 0.9008 | Test: loss 0.5444 acc 0.8994 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9008\n",
      "Epoch 022/30 | Train: loss 0.3626 acc 0.9533 | Val: loss 0.5252 acc 0.9038 | Test: loss 0.5155 acc 0.9048 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9038\n",
      "Epoch 023/30 | Train: loss 0.3469 acc 0.9565 | Val: loss 0.4990 acc 0.9067 | Test: loss 0.4905 acc 0.9106 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9067\n",
      "Epoch 024/30 | Train: loss 0.3258 acc 0.9558 | Val: loss 0.4898 acc 0.9052 | Test: loss 0.4810 acc 0.9077 | LR: 5.00e-05\n",
      "Epoch 025/30 | Train: loss 0.3127 acc 0.9619 | Val: loss 0.4684 acc 0.9126 | Test: loss 0.4590 acc 0.9160 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9126\n",
      "Epoch 026/30 | Train: loss 0.2839 acc 0.9658 | Val: loss 0.4510 acc 0.9101 | Test: loss 0.4396 acc 0.9165 | LR: 5.00e-05\n",
      "Epoch 027/30 | Train: loss 0.2789 acc 0.9643 | Val: loss 0.4504 acc 0.9106 | Test: loss 0.4408 acc 0.9141 | LR: 5.00e-05\n",
      "Epoch 028/30 | Train: loss 0.2642 acc 0.9685 | Val: loss 0.4269 acc 0.9155 | Test: loss 0.4181 acc 0.9219 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9155\n",
      "Epoch 029/30 | Train: loss 0.2540 acc 0.9692 | Val: loss 0.4188 acc 0.9160 | Test: loss 0.4089 acc 0.9258 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9160\n",
      "Epoch 030/30 | Train: loss 0.2407 acc 0.9675 | Val: loss 0.3983 acc 0.9184 | Test: loss 0.3863 acc 0.9277 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9184\n",
      "\n",
      "============================================================\n",
      "FINAL EVALUATION\n",
      "============================================================\n",
      "Training curves saved in ./results/yolov5_cls_seed1\n",
      "Saved: ./results/yolov5_cls_seed1\\probs_yolov5.csv\n",
      "Saved: ./results/yolov5_cls_seed1\\test_probs_yolov5_seed1.csv\n",
      "\n",
      "============================================================\n",
      "YOLOV5 TRAINING SUMMARY\n",
      "============================================================\n",
      "Data split seed: 1\n",
      "Best epoch: 30\n",
      "Best validation accuracy: 0.9184\n",
      "Best validation loss: 0.3983\n",
      "Final test accuracy: 0.9277\n",
      "Final test loss: 0.3863\n",
      "Total epochs trained: 30\n",
      "\n",
      "Saved files:\n",
      "- Checkpoint: ./results/yolov5_cls_seed1\\best_yolov5.pt\n",
      "- Accuracy curve: ./results/yolov5_cls_seed1\\accuracy_yolov5.png\n",
      "- Loss curve: ./results/yolov5_cls_seed1\\loss_yolov5.png\n",
      "- History: ./results/yolov5_cls_seed1\\history_yolov5.json\n",
      "- Split indices: ./results/yolov5_cls_seed1\\split_indices_seed_1.json\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== REAL YOLOv5-CLS Experiments ===\")\n",
    "\n",
    "h1_yolo_real, ckpt1_yolo_real = run_experiment(\n",
    "    model_type=\"yolov5_cls\",\n",
    "    data_root=r\"C:\\Users\\hp\\Downloads\\102flowers\",\n",
    "    split_seed=1,\n",
    "    out_dir=\"./results/yolov5_cls_seed1\",\n",
    "    epochs=30,\n",
    "    lr=5e-5,\n",
    "    freeze_backbone=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78160f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2026-1-14 Python-3.13.5 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training YOLOV5_CLS - Split Seed: 2\n",
      "============================================================\n",
      "Loading REAL YOLOv5-CLS checkpoint: yolov5s-cls.pt\n",
      "Model: yolov5\n",
      "Total parameters: 4,303,142\n",
      "Trainable parameters: 788,582\n",
      "Frozen parameters: 3,514,560\n",
      "Learning rate: 5e-05\n",
      "\n",
      "Starting training for 30 epochs...\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 001/30 | Train: loss 4.2770 acc 0.1295 | Val: loss 3.9111 acc 0.2296 | Test: loss 3.8800 acc 0.2515 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.2296\n",
      "Epoch 002/30 | Train: loss 3.5514 acc 0.3129 | Val: loss 3.3129 acc 0.3810 | Test: loss 3.2716 acc 0.4111 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.3810\n",
      "Epoch 003/30 | Train: loss 2.9393 acc 0.5000 | Val: loss 2.7868 acc 0.5056 | Test: loss 2.7405 acc 0.5215 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.5056\n",
      "Epoch 004/30 | Train: loss 2.4117 acc 0.6241 | Val: loss 2.3262 acc 0.6014 | Test: loss 2.2819 acc 0.6147 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.6014\n",
      "Epoch 005/30 | Train: loss 2.0022 acc 0.6971 | Val: loss 1.9736 acc 0.6781 | Test: loss 1.9328 acc 0.6880 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.6781\n",
      "Epoch 006/30 | Train: loss 1.6827 acc 0.7567 | Val: loss 1.7105 acc 0.7206 | Test: loss 1.6722 acc 0.7300 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7206\n",
      "Epoch 007/30 | Train: loss 1.4280 acc 0.8136 | Val: loss 1.4938 acc 0.7660 | Test: loss 1.4555 acc 0.7710 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7660\n",
      "Epoch 008/30 | Train: loss 1.2319 acc 0.8395 | Val: loss 1.3309 acc 0.7914 | Test: loss 1.2923 acc 0.8042 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.7914\n",
      "Epoch 009/30 | Train: loss 1.0778 acc 0.8679 | Val: loss 1.1923 acc 0.8129 | Test: loss 1.1545 acc 0.8257 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8129\n",
      "Epoch 010/30 | Train: loss 0.9691 acc 0.8757 | Val: loss 1.0897 acc 0.8173 | Test: loss 1.0509 acc 0.8389 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8173\n",
      "Epoch 011/30 | Train: loss 0.8568 acc 0.8901 | Val: loss 0.9885 acc 0.8334 | Test: loss 0.9508 acc 0.8457 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8334\n",
      "Epoch 012/30 | Train: loss 0.7707 acc 0.9035 | Val: loss 0.9252 acc 0.8422 | Test: loss 0.8867 acc 0.8618 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8422\n",
      "Epoch 013/30 | Train: loss 0.7060 acc 0.9067 | Val: loss 0.8447 acc 0.8530 | Test: loss 0.8058 acc 0.8691 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8530\n",
      "Epoch 014/30 | Train: loss 0.6482 acc 0.9174 | Val: loss 0.8029 acc 0.8627 | Test: loss 0.7626 acc 0.8794 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8627\n",
      "Epoch 015/30 | Train: loss 0.6034 acc 0.9179 | Val: loss 0.7514 acc 0.8691 | Test: loss 0.7115 acc 0.8804 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8691\n",
      "Epoch 016/30 | Train: loss 0.5603 acc 0.9216 | Val: loss 0.7099 acc 0.8774 | Test: loss 0.6736 acc 0.8882 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8774\n",
      "Epoch 017/30 | Train: loss 0.5084 acc 0.9336 | Val: loss 0.6817 acc 0.8808 | Test: loss 0.6422 acc 0.8887 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8808\n",
      "Epoch 018/30 | Train: loss 0.4777 acc 0.9389 | Val: loss 0.6331 acc 0.8911 | Test: loss 0.5960 acc 0.8955 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8911\n",
      "Epoch 019/30 | Train: loss 0.4484 acc 0.9397 | Val: loss 0.6132 acc 0.8911 | Test: loss 0.5760 acc 0.8975 | LR: 5.00e-05\n",
      "Epoch 020/30 | Train: loss 0.4156 acc 0.9492 | Val: loss 0.5934 acc 0.8955 | Test: loss 0.5545 acc 0.8989 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.8955\n",
      "Epoch 021/30 | Train: loss 0.3913 acc 0.9463 | Val: loss 0.5661 acc 0.9003 | Test: loss 0.5280 acc 0.8989 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9003\n",
      "Epoch 022/30 | Train: loss 0.3742 acc 0.9482 | Val: loss 0.5338 acc 0.9043 | Test: loss 0.4983 acc 0.9014 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9043\n",
      "Epoch 023/30 | Train: loss 0.3506 acc 0.9533 | Val: loss 0.5262 acc 0.9038 | Test: loss 0.4872 acc 0.9067 | LR: 5.00e-05\n",
      "Epoch 024/30 | Train: loss 0.3305 acc 0.9573 | Val: loss 0.5110 acc 0.9082 | Test: loss 0.4714 acc 0.9082 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9082\n",
      "Epoch 025/30 | Train: loss 0.3114 acc 0.9607 | Val: loss 0.4943 acc 0.9086 | Test: loss 0.4563 acc 0.9102 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9086\n",
      "Epoch 026/30 | Train: loss 0.2900 acc 0.9602 | Val: loss 0.4819 acc 0.9072 | Test: loss 0.4447 acc 0.9106 | LR: 5.00e-05\n",
      "Epoch 027/30 | Train: loss 0.2798 acc 0.9660 | Val: loss 0.4668 acc 0.9101 | Test: loss 0.4291 acc 0.9136 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9101\n",
      "Epoch 028/30 | Train: loss 0.2642 acc 0.9651 | Val: loss 0.4552 acc 0.9086 | Test: loss 0.4182 acc 0.9160 | LR: 5.00e-05\n",
      "Epoch 029/30 | Train: loss 0.2517 acc 0.9707 | Val: loss 0.4413 acc 0.9121 | Test: loss 0.4037 acc 0.9194 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9121\n",
      "Epoch 030/30 | Train: loss 0.2414 acc 0.9724 | Val: loss 0.4302 acc 0.9135 | Test: loss 0.3925 acc 0.9199 | LR: 5.00e-05\n",
      "✓ New best model saved! Val Acc: 0.9135\n",
      "\n",
      "============================================================\n",
      "FINAL EVALUATION\n",
      "============================================================\n",
      "Training curves saved in ./results/yolov5_cls_seed2\n",
      "Saved: ./results/yolov5_cls_seed2\\probs_yolov5.csv\n",
      "Saved: ./results/yolov5_cls_seed2\\test_probs_yolov5_seed2.csv\n",
      "\n",
      "============================================================\n",
      "YOLOV5 TRAINING SUMMARY\n",
      "============================================================\n",
      "Data split seed: 2\n",
      "Best epoch: 30\n",
      "Best validation accuracy: 0.9135\n",
      "Best validation loss: 0.4302\n",
      "Final test accuracy: 0.9199\n",
      "Final test loss: 0.3925\n",
      "Total epochs trained: 30\n",
      "\n",
      "Saved files:\n",
      "- Checkpoint: ./results/yolov5_cls_seed2\\best_yolov5.pt\n",
      "- Accuracy curve: ./results/yolov5_cls_seed2\\accuracy_yolov5.png\n",
      "- Loss curve: ./results/yolov5_cls_seed2\\loss_yolov5.png\n",
      "- History: ./results/yolov5_cls_seed2\\history_yolov5.json\n",
      "- Split indices: ./results/yolov5_cls_seed2\\split_indices_seed_2.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "h2_yolo_real, ckpt2_yolo_real = run_experiment(\n",
    "    model_type=\"yolov5_cls\",\n",
    "    data_root=r\"C:\\Users\\hp\\Downloads\\102flowers\",\n",
    "    split_seed=2,\n",
    "    out_dir=\"./results/yolov5_cls_seed2\",\n",
    "    epochs=30,\n",
    "    lr=5e-5,\n",
    "    freeze_backbone=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63a462c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RESNET50 EXPERIMENTS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize results dictionary\n",
    "all_results = {}\n",
    "\n",
    "# Run ResNet50 experiments\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESNET50 EXPERIMENTS\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c97021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training RESNET50 - Split Seed: 1\n",
      "============================================================\n",
      "Model: resnet50\n",
      "Total parameters: 23,717,030\n",
      "Trainable parameters: 208,998\n",
      "Frozen parameters: 23,508,032\n",
      "Learning rate: 0.0001\n",
      "Batch size: 32\n",
      "Epochs: 35\n",
      "\n",
      "Starting training for 35 epochs...\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 001/35 | Train: loss 4.2580 acc 0.0984 | Val: loss 3.8844 acc 0.2086 | Test: loss 3.9039 acc 0.1851 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.2086\n",
      "Epoch 002/35 | Train: loss 3.6169 acc 0.3000 | Val: loss 3.3204 acc 0.4045 | Test: loss 3.3413 acc 0.3994 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.4045\n",
      "Epoch 003/35 | Train: loss 3.0968 acc 0.4778 | Val: loss 2.8569 acc 0.5369 | Test: loss 2.8847 acc 0.5371 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.5369\n",
      "Epoch 004/35 | Train: loss 2.6551 acc 0.5989 | Val: loss 2.4665 acc 0.6019 | Test: loss 2.4999 acc 0.6133 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.6019\n",
      "Epoch 005/35 | Train: loss 2.2971 acc 0.6776 | Val: loss 2.1829 acc 0.6497 | Test: loss 2.2072 acc 0.6616 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.6497\n",
      "Epoch 006/35 | Train: loss 2.0138 acc 0.7284 | Val: loss 1.9065 acc 0.7176 | Test: loss 1.9328 acc 0.7236 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7176\n",
      "Epoch 007/35 | Train: loss 1.7705 acc 0.7623 | Val: loss 1.7239 acc 0.7557 | Test: loss 1.7319 acc 0.7749 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7557\n",
      "Epoch 008/35 | Train: loss 1.5824 acc 0.7958 | Val: loss 1.5444 acc 0.7763 | Test: loss 1.5538 acc 0.7891 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7763\n",
      "Epoch 009/35 | Train: loss 1.4188 acc 0.8244 | Val: loss 1.4421 acc 0.7875 | Test: loss 1.4528 acc 0.7905 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.7875\n",
      "Epoch 010/35 | Train: loss 1.2972 acc 0.8366 | Val: loss 1.2881 acc 0.8134 | Test: loss 1.2902 acc 0.8203 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.8134\n",
      "Epoch 011/35 | Train: loss 1.1851 acc 0.8490 | Val: loss 1.2112 acc 0.8202 | Test: loss 1.2145 acc 0.8286 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.8202\n",
      "Epoch 012/35 | Train: loss 1.0976 acc 0.8642 | Val: loss 1.1509 acc 0.8285 | Test: loss 1.1546 acc 0.8374 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.8285\n",
      "Epoch 013/35 | Train: loss 1.0162 acc 0.8639 | Val: loss 1.0775 acc 0.8344 | Test: loss 1.0799 acc 0.8472 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.8344\n",
      "Epoch 014/35 | Train: loss 0.9369 acc 0.8813 | Val: loss 1.0083 acc 0.8471 | Test: loss 1.0111 acc 0.8501 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.8471\n",
      "Epoch 015/35 | Train: loss 0.8727 acc 0.8937 | Val: loss 0.9623 acc 0.8481 | Test: loss 0.9656 acc 0.8516 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.8481\n",
      "Epoch 016/35 | Train: loss 0.8212 acc 0.9006 | Val: loss 0.8989 acc 0.8578 | Test: loss 0.9072 acc 0.8623 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.8578\n",
      "Epoch 017/35 | Train: loss 0.7906 acc 0.8964 | Val: loss 0.8600 acc 0.8647 | Test: loss 0.8609 acc 0.8604 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.8647\n",
      "Epoch 018/35 | Train: loss 0.7435 acc 0.9003 | Val: loss 0.8229 acc 0.8661 | Test: loss 0.8221 acc 0.8672 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.8661\n",
      "Epoch 019/35 | Train: loss 0.6960 acc 0.9072 | Val: loss 0.7963 acc 0.8666 | Test: loss 0.8024 acc 0.8691 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.8666\n",
      "Epoch 020/35 | Train: loss 0.6685 acc 0.9094 | Val: loss 0.7700 acc 0.8696 | Test: loss 0.7674 acc 0.8730 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.8696\n",
      "Epoch 021/35 | Train: loss 0.6390 acc 0.9172 | Val: loss 0.7359 acc 0.8764 | Test: loss 0.7410 acc 0.8691 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.8764\n",
      "Epoch 022/35 | Train: loss 0.6072 acc 0.9187 | Val: loss 0.6979 acc 0.8774 | Test: loss 0.6968 acc 0.8784 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.8774\n",
      "Epoch 023/35 | Train: loss 0.5839 acc 0.9209 | Val: loss 0.6835 acc 0.8852 | Test: loss 0.6938 acc 0.8765 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.8852\n",
      "Epoch 024/35 | Train: loss 0.5591 acc 0.9255 | Val: loss 0.6673 acc 0.8832 | Test: loss 0.6676 acc 0.8794 | LR: 1.00e-04\n",
      "Epoch 025/35 | Train: loss 0.5373 acc 0.9272 | Val: loss 0.6589 acc 0.8876 | Test: loss 0.6691 acc 0.8745 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.8876\n",
      "Epoch 026/35 | Train: loss 0.5175 acc 0.9231 | Val: loss 0.6369 acc 0.8857 | Test: loss 0.6461 acc 0.8774 | LR: 1.00e-04\n",
      "Epoch 027/35 | Train: loss 0.4967 acc 0.9299 | Val: loss 0.6254 acc 0.8852 | Test: loss 0.6319 acc 0.8755 | LR: 1.00e-04\n",
      "Epoch 028/35 | Train: loss 0.4899 acc 0.9294 | Val: loss 0.5956 acc 0.8901 | Test: loss 0.6011 acc 0.8833 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.8901\n",
      "Epoch 029/35 | Train: loss 0.4605 acc 0.9360 | Val: loss 0.5819 acc 0.8872 | Test: loss 0.5871 acc 0.8833 | LR: 1.00e-04\n",
      "Epoch 030/35 | Train: loss 0.4417 acc 0.9416 | Val: loss 0.5670 acc 0.8911 | Test: loss 0.5740 acc 0.8804 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.8911\n",
      "Epoch 031/35 | Train: loss 0.4294 acc 0.9394 | Val: loss 0.5630 acc 0.8876 | Test: loss 0.5735 acc 0.8857 | LR: 1.00e-04\n",
      "Epoch 032/35 | Train: loss 0.4243 acc 0.9380 | Val: loss 0.5592 acc 0.8881 | Test: loss 0.5709 acc 0.8823 | LR: 1.00e-04\n",
      "Epoch 033/35 | Train: loss 0.4049 acc 0.9419 | Val: loss 0.5413 acc 0.8847 | Test: loss 0.5413 acc 0.8911 | LR: 1.00e-04\n",
      "Epoch 034/35 | Train: loss 0.3932 acc 0.9441 | Val: loss 0.5193 acc 0.8984 | Test: loss 0.5237 acc 0.8916 | LR: 1.00e-04\n",
      "✓ New best model saved! Val Acc: 0.8984\n",
      "Epoch 035/35 | Train: loss 0.3811 acc 0.9458 | Val: loss 0.5358 acc 0.8925 | Test: loss 0.5460 acc 0.8843 | LR: 1.00e-04\n",
      "\n",
      "============================================================\n",
      "FINAL EVALUATION\n",
      "============================================================\n",
      "Saved: ./results/resnet50_seed1\\test_probs_resnet50_seed1.csv\n",
      "\n",
      "============================================================\n",
      "RESNET50 TRAINING SUMMARY\n",
      "============================================================\n",
      "Data split seed: 1\n",
      "Best epoch: 34\n",
      "Best validation accuracy: 0.8984\n",
      "Best validation loss: 0.5193\n",
      "Final test accuracy: 0.8916\n",
      "Final test loss: 0.5237\n",
      "Total epochs trained: 35\n",
      "\n",
      "Saved files:\n",
      "- Checkpoint: ./results/resnet50_seed1\\best_resnet50.pt\n",
      "- Accuracy curve: ./results/resnet50_seed1\\training_curves_resnet50.png\n",
      "- Loss curve: ./results/resnet50_seed1\\training_curves_resnet50.png\n",
      "- History: ./results/resnet50_seed1\\history_resnet50.json\n",
      "- Split indices: ./results/resnet50_seed1\\split_indices_seed_1.json\n",
      "- Test probabilities: ./results/resnet50_seed1\\test_probs_resnet50_seed1.csv\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'all_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      1\u001b[39m h1_resnet, ckpt1_resnet = run_experiment(\n\u001b[32m      2\u001b[39m         model_type=\u001b[33m\"\u001b[39m\u001b[33mresnet50\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m         data_root=\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mhp\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mDownloads\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33m102flowers\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m         freeze_backbone=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      9\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mall_results\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mresnet50_seed1\u001b[39m\u001b[33m\"\u001b[39m] = h1_resnet\n",
      "\u001b[31mNameError\u001b[39m: name 'all_results' is not defined"
     ]
    }
   ],
   "source": [
    "h1_resnet, ckpt1_resnet = run_experiment(\n",
    "        model_type=\"resnet50\",\n",
    "        data_root=\"C:\\\\Users\\\\hp\\\\Downloads\\\\102flowers\",\n",
    "        split_seed=1,\n",
    "        out_dir=\"./results/resnet50_seed1\",\n",
    "        epochs=35,\n",
    "        lr=1e-4,\n",
    "        freeze_backbone=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1591588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results[\"resnet50_seed1\"] = h1_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2edb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training RESNET50 - Split Seed: 2\n",
      "============================================================\n",
      "Model: resnet50\n",
      "Total parameters: 23,717,030\n",
      "Trainable parameters: 208,998\n",
      "Frozen parameters: 23,508,032\n",
      "Learning rate: 0.0001\n",
      "Batch size: 32\n",
      "Epochs: 35\n",
      "\n",
      "Starting training for 35 epochs...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "h2_resnet, ckpt2_resnet = run_experiment(\n",
    "        model_type=\"resnet50\",\n",
    "        data_root=\"C:\\\\Users\\\\hp\\\\Downloads\\\\102flowers\",\n",
    "        split_seed=2,\n",
    "        out_dir=\"./results/resnet50_seed2\",\n",
    "        epochs=35,\n",
    "        lr=1e-4,\n",
    "        freeze_backbone=True,\n",
    "    )\n",
    "all_results[\"resnet50_seed2\"] = h2_resnet\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c817e401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all three models comparison\n",
    "all_results = {}\n",
    "all_results[\"vgg19_seed1\"] = h1_vgg  # from your previous run\n",
    "all_results[\"vgg19_seed2\"] = h2_vgg  # from your previous run\n",
    "all_results[\"resnet50_seed1\"] = h1_resnet\n",
    "all_results[\"resnet50_seed2\"] = h2_resnet\n",
    "all_results[\"yolov5_seed1\"] = h1_yolo  # from your previous run\n",
    "all_results[\"yolov5_seed2\"] = h2_yolo  # from your previous run\n",
    "\n",
    "# Generate comparison report\n",
    "generate_comparison_report(all_results)\n",
    "This will give you a complete comparison bet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
